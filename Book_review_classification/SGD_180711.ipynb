{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 sentence is vectorised\n",
      "500 sentence is vectorised\n",
      "0 sentence is vectorised\n",
      "500 sentence is vectorised\n",
      "2000 sentence is vectorised\n"
     ]
    }
   ],
   "source": [
    "#データをベクトル化する\n",
    "#かつ、データについてshuffleする。\n",
    "# -*- coding: utf-8 -*-\n",
    "import math\n",
    "import csv\n",
    "import os\n",
    "import json\n",
    "import pickle\n",
    "import random\n",
    "\n",
    "shuffle_repeat = 100\n",
    "\n",
    "def sentence_vectorize():\n",
    "    \n",
    "    #positive,negativeすべて合わせた文のインデックス用\n",
    "    #後でシャッフル呼び出し時に用いる\n",
    "    total_index = 0\n",
    "    \n",
    "    #positive,negative両方用\n",
    "    all_sentence_vectorized = []\n",
    "    #positive : sign =1, negative : sign = -1\n",
    "    with open(\"./data/books/positive.review\",mode = \"r\", encoding = \"utf-8\") as p:\n",
    "        index = 0   #各文にインデックスを付ける。シャッフル呼び出し用\n",
    "        positive = []\n",
    "        for line in p:\n",
    "            \n",
    "            oneline = line.split(\" \") #まだ　\" \" でsplitしただけ\n",
    "            one_sentence = [0 for _ in range(200000)]  #これから一文をベクトル化する\n",
    "            \n",
    "            #一文内の各id:countに対する処理\n",
    "            for one_id_count_set in oneline:\n",
    "                id_,count_ = one_id_count_set.split(\":\")\n",
    "                # 文末のid:count用\n",
    "                count_ = count_.strip() \n",
    "                \n",
    "                one_sentence[int(id_)] += int(count_) \n",
    "\n",
    "            #一文に対する処理　ここまで\n",
    "            #one_sentenceを記録する、ただし、sign,indexをつける必要がある\n",
    "            \n",
    "            #sign, index用も込のリスト、すなわち\n",
    "            #[ sign ,  index,  [ 200000次元のリスト ]]　とする。\n",
    "            \n",
    "            \n",
    "            \n",
    "            if index % 500 == 0:\n",
    "                print(str(index) + \" sentence is vectorised\")\n",
    "            \n",
    "            positive.append(one_sentence)\n",
    "                \n",
    "            #各sentenceに固有\n",
    "            index +=1\n",
    "        # shuffle  \n",
    "        for i in range(shuffle_repeat):\n",
    "            positive = random.sample(positive,len(positive))\n",
    "        with open(\"./positive.review.vector\",\"wb\") as pp:\n",
    "            pickle.dump(positive,pp)\n",
    "        \n",
    "        #negative_dataの各文章に対するインデックス開始は1から\n",
    "        #total_indexは全センテンス用\n",
    "        total_index += index\n",
    "        all_sentence_vectorized.append(positive)\n",
    "\n",
    "    with open(\"./data/books/negative.review\",mode = \"r\", encoding = \"utf-8\") as n:\n",
    "        index = 0   #各文にインデックスを付ける。シャッフル呼び出し用\n",
    "        negative = []\n",
    "        for line in n:\n",
    "            \n",
    "            oneline = line.split(\" \") #まだ　\" \" でsplitしただけ\n",
    "            one_sentence = [0 for _ in range(200000)]  #これから一文をベクトル化する\n",
    "            \n",
    "            #一文内の各id:countに対する処理\n",
    "            for one_id_count_set in oneline:\n",
    "                id_,count_ = one_id_count_set.split(\":\")\n",
    "                # 文末のid:count用\n",
    "                count_ = count_.strip() \n",
    "                \n",
    "                one_sentence[int(id_)] += int(count_) \n",
    "            #一文に対する処理　ここまで\n",
    "            #one_sentenceを記録する、ただし、sign,indexをつける必要がある\n",
    "            \n",
    "            #sign, index用も込のリスト、すなわち\n",
    "            #[ sign ,  index,  [ 200000次元のリスト ]]　とする。\n",
    "            \n",
    "            #sentence_to_be_recorded = [index,-1,one_sentence]\n",
    "            \n",
    "            if index % 500 == 0:\n",
    "                print(str(index) + \" sentence is vectorised\")\n",
    "            \n",
    "            negative.append(one_sentence)\n",
    "                \n",
    "            #各sentenceに固有\n",
    "            index +=1\n",
    "            total_index +=1 \n",
    "        for i in range(shuffle_repeat):\n",
    "            negative = random.sample(negative,len(negative))\n",
    "    all_sentence_vectorized.append(negative)\n",
    "    \n",
    "   \n",
    "    with open(\"./negative.review.vector\",\"wb\") as nn:\n",
    "            pickle.dump(negative,nn) \n",
    "            \n",
    "        \n",
    "    with open(\"./all_sentence_vectorised.vector\",\"wb\") as f:\n",
    "        pickle.dump(all_sentence_vectorized,f)\n",
    "        \n",
    "    print(str(total_index) + \" sentence is vectorised\")\n",
    "    \n",
    "sentence_vectorize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split train=0.8, dev = 0.1, test = 0.1\n",
    "#bias is needed\n",
    "\n",
    "import random\n",
    "import pickle\n",
    "\n",
    "def data_spliter():\n",
    "    p_train = []\n",
    "    p_dev = []\n",
    "    p_test = []\n",
    "    \n",
    "    n_train = []\n",
    "    n_dev = []\n",
    "    n_test = []\n",
    "    \n",
    "    with open(\"positive.review.vector\",\"rb\") as p:\n",
    "        p_list = pickle.load(p)\n",
    "\n",
    "        for i in range(len( p_list)):\n",
    "            if i <800:\n",
    "                p_train.append(p_list[i])\n",
    "            elif i >= 800 and i <= 900:\n",
    "                p_dev.append(p_list[i])\n",
    "            else:\n",
    "                p_test.append(p_list[i])\n",
    "                \n",
    "    with open(\"negative.review.vector\",\"rb\") as n:\n",
    "        n_list = pickle.load(n)\n",
    "\n",
    "        for i in range(len(n_list)):\n",
    "            if i <800:\n",
    "                n_train.append(n_list[i])\n",
    "            elif i >= 800 and i < 900:\n",
    "                n_dev.append(n_list[i])\n",
    "            else:\n",
    "                n_test.append(n_list[i])    \n",
    "        \n",
    "    with open(\"./train_dev_test/p_train\",\"wb\") as f:\n",
    "        pickle.dump(p_train,f)\n",
    "\n",
    "    with open(\"./train_dev_test/p_dev\",\"wb\") as f:\n",
    "        pickle.dump(p_dev,f)\n",
    "\n",
    "    with open(\"./train_dev_test/p_test\",\"wb\") as f:\n",
    "        pickle.dump(p_test,f)\n",
    "        \n",
    "    with open(\"./train_dev_test/n_train\",\"wb\") as f:\n",
    "        pickle.dump(n_train,f)\n",
    "\n",
    "    with open(\"./train_dev_test/n_dev\",\"wb\") as f:\n",
    "        pickle.dump(n_dev,f)\n",
    "\n",
    "    with open(\"./train_dev_test/n_test\",\"wb\") as f:\n",
    "        pickle.dump(n_test,f)\n",
    "        \n",
    "data_spliter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function\n",
    "\n",
    "import math\n",
    "def sigmoid(xx):\n",
    "    if xx > 0:\n",
    "        return (1 / (1 + math.exp(-xx)))\n",
    "    else:\n",
    "        return (1 - 1 / (1 + math.exp(xx)))\n",
    "        \n",
    "\n",
    "def v_dot(list_x,list_y): #内積\n",
    "    sums = 0\n",
    "    for i in range(len(list_x)):\n",
    "        sums+= list_x[i] * list_y[i]\n",
    "    return sums\n",
    "\n",
    "def v_plus(list_x,list_y):\n",
    "    result = [0 for _ in range(len(list_x))]\n",
    "    for i in range(len(list_x)):\n",
    "        result[i] = list_x[i] + list_y[i]\n",
    "    return result    \n",
    "\n",
    "def v_minus(list_x,list_y):\n",
    "    result = [0 for _ in range(len(list_x))]\n",
    "    for i in range(len(list_x)):\n",
    "        result[i] = list_x[i] - list_y[i]\n",
    "    return result    \n",
    "\n",
    "def v_a_fold(a,list_x): #vectorの定数倍\n",
    "    for i in list_x:\n",
    "        i = a * i\n",
    "    return list_x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([965, 521, 923, 370, 673, 279, 902, 644, 156, 946, 854, 209, 203,\n",
       "       207, 441, 157, 830, 321, 257, 330])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.random.choice([i for i in range(1000)],20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "def load_train(batch_size):\n",
    "    p_ret = []\n",
    "    n_ret = []\n",
    "    p_index = np.random.choice([i for i in range(800)],batch_size)\n",
    "    n_index = np.random.choice([i for i in range(800)],batch_size)\n",
    "    with open(\"./train_dev_test/p_train\",\"rb\") as p:\n",
    "        with open(\"./train_dev_test/n_train\",\"rb\") as n:\n",
    "            p_train = pickle.load(p)\n",
    "            n_train = pickle.load(n)\n",
    "            \n",
    "            for _ in p_index:\n",
    "                p_ret.append(p_train[_])\n",
    "                \n",
    "            for _ in n_index:\n",
    "                n_ret.append(n_train[_])\n",
    "    return p_ret, n_ret\n",
    "\n",
    "\n",
    "\n",
    "def training(w,b,p_batch,n_batch,learning_rate,mini_batch_size):\n",
    "    ips = 10 ** (-7)\n",
    "    \n",
    "    loss = 0\n",
    "    one_iter = np.array( [0 for i in range(200000)])\n",
    "    one_b = 0\n",
    "    \n",
    "    # 1 epochの中でp_batch(size = load_batch), n_batch(size = load_batch) 取ってきて\n",
    "    #　その中からランダムで　mini_batch　個のデータで　1epoch回す。\n",
    "    \n",
    "    \"\"\"\n",
    "    for batch in p_train_batchs :\n",
    "        y = 1\n",
    "        one_iter = v_plus(one_iter ,  v_a_fold(((-1) * (y) * sigmoid((-1) * y * np.dot(w,batch))),batch) )\n",
    "        one_b = one_b + (-1) * y * 1 * sigmoid((-1) * y * np.dot(w,batch))\n",
    "        loss += (-1) * math.log(ips + sigmoid(y * np.dot(w,one_iter) + b))    \n",
    "        #w = np.add(w ,(-1)* (learning_rate / len(batch)) * one_iter)\n",
    "        \n",
    "    w = np.add(w, v_a_fold((-1)* (learning_rate / len(p_train_batchs)) , one_iter) )\n",
    "    #b = np.add( b,  ((-1)* (learning_rate / len(batch)) )* one_b)\n",
    "    bias = bias - ((-1)* (learning_rate / len(p_train_batchs)) )* one_b      \n",
    "    print(\"Loss: \" + str(loss))\n",
    "    \n",
    "    loss = 0\n",
    "    one_iter = np.array( [0 for i in range(200000)])\n",
    "    one_b = 0\n",
    "    for batch in n_train_batchs :\n",
    "        y = -1\n",
    "        one_iter = v_plus(one_iter ,  v_a_fold(((-1) * (y) * sigmoid((-1) * y * np.dot(w,batch))),batch) )\n",
    "        one_b = one_b + (-1) * y * 1 * sigmoid((-1) * y * np.dot(w,batch))\n",
    "        loss += (-1) * math.log(ips + sigmoid(y * np.dot(w,one_iter) + b))    \n",
    "    #w = np.add(w ,(-1)* (learning_rate / len(batch)) * one_iter) \n",
    "    w = np.add(w, v_a_fold((-1)* (learning_rate / len(n_train_batchs)) , one_iter) )\n",
    "    #b = np.add( b,  ((-1)* (learning_rate / len(batch)) )* one_b)\n",
    "    bias = bias - ((-1)* (learning_rate / len(n_train_batchs)) )* one_b      \n",
    "    print(\"Loss: \" + str(loss))    \n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    #print(\"p_batch\"+str(p_batch))\n",
    "\n",
    "    indexed_sentence = []\n",
    "    for sentence in p_batch:\n",
    "        indexed_sentence.append([1,sentence])\n",
    "        \n",
    "    for sentence in n_batch:\n",
    "        indexed_sentence.append([-1,sentence])\n",
    "        \n",
    "    batch_to_be_used_index = np.random.choice(len(indexed_sentence),mini_batch_size)\n",
    "    batch_to_be_used = []\n",
    "    for _ in batch_to_be_used_index:\n",
    "        batch_to_be_used.append(indexed_sentence[_])\n",
    "    \n",
    "    #print(batch_to_be_used)\n",
    "    Loss = 0\n",
    "    delL_devide_delw = np.array([0 for _ in range(200000)])\n",
    "    delL_devide_delw_for_b = 0\n",
    "    \n",
    "    \"\"\"\n",
    "    delL_devide_delw = -y * sigmoid(-y *( np.dot(w,x) + b)) * x\n",
    "    delL_devide_delw_for_b  = (-y) * 1 * sigmoid(-y *( np.dot(w,x) + b))\n",
    "    \n",
    "    \"\"\"\n",
    "    #w,b  : fixed\n",
    "    for pn_sentence in batch_to_be_used:\n",
    "        y = pn_sentence[0]\n",
    "        #print(y)\n",
    "        x = pn_sentence[1]\n",
    "        x = np.array(x)\n",
    "        #print(x,len(w))\n",
    "        delL_devide_delw = np.array(delL_devide_delw) + (-1) * y * sigmoid((-1) * (y) * (np.dot(w,x)) )* x\n",
    "        delL_devide_delw_for_b += (-1) * y * sigmoid((-1) * (y) * (np.dot(w,x)) )* 1 # x内に成分1がappendされて,wxを考える\n",
    "        Loss += (-1) * math.log(ips +sigmoid(y * np.dot(w,x)))\n",
    "    #learning\n",
    "    w = w - ( learning_rate / len(batch_to_be_used) ) * delL_devide_delw\n",
    "    b  =  b -  ( learning_rate / len(batch_to_be_used) ) * delL_devide_delw_for_b\n",
    "    Loss = Loss / len(batch_to_be_used)\n",
    "    \n",
    "    return w,b,Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dev():\n",
    "    p_dev = []\n",
    "    n_dev = []\n",
    "    with open(\"./train_dev_test/p_dev\",\"rb\") as p:\n",
    "        with open(\"./train_dev_test/n_dev\",\"rb\") as n:\n",
    "            p_dev = pickle.load(p)\n",
    "            n_dev = pickle.load(n)\n",
    "    return p_dev, n_dev\n",
    "    \n",
    "def accuracy_eval(w,b):\n",
    "    p_dev,n_dev = load_dev()\n",
    "    correct = 0\n",
    "    all_count = 0\n",
    "    \n",
    "    for _ in p_dev:\n",
    "        all_count += 1\n",
    "        y_ = 1\n",
    "        _ = np.array(_)\n",
    "        if np.dot(w,_) + b >=0:\n",
    "            correct += 1\n",
    "    for _ in n_dev:\n",
    "        all_count += 1\n",
    "        y_ = -1\n",
    "        _ = np.array(_)\n",
    "        if ((np.dot(w,_) + b)) <0:\n",
    "            correct += 1    \n",
    "    accuracy = correct * 100 / all_count\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch1 end\n",
      "Loss: 4.381897889793725\n",
      "accuracy: 45.27363184079602\n",
      "epoch2 end\n",
      "Loss: 3.712558361879265\n",
      "accuracy: 51.74129353233831\n",
      "epoch3 end\n",
      "Loss: 6.080853125201996\n",
      "accuracy: 53.73134328358209\n",
      "epoch4 end\n",
      "Loss: 2.1219241676001426\n",
      "accuracy: 53.233830845771145\n",
      "epoch5 end\n",
      "Loss: 2.3984581164306835\n",
      "accuracy: 52.7363184079602\n",
      "epoch6 end\n",
      "Loss: 0.7628036150170348\n",
      "accuracy: 52.7363184079602\n",
      "epoch7 end\n",
      "Loss: 0.8080932459550401\n",
      "accuracy: 52.23880597014925\n",
      "epoch8 end\n",
      "Loss: 0.4894869423420161\n",
      "accuracy: 52.23880597014925\n",
      "epoch9 end\n",
      "Loss: 1.667928639163753\n",
      "accuracy: 51.74129353233831\n",
      "epoch10 end\n",
      "Loss: 2.575780077199011\n",
      "accuracy: 50.24875621890547\n",
      "epoch11 end\n",
      "Loss: 0.8645184737878164\n",
      "accuracy: 50.24875621890547\n",
      "epoch12 end\n",
      "Loss: 3.6344424357934813\n",
      "accuracy: 51.243781094527364\n",
      "epoch13 end\n",
      "Loss: 4.649678683042163\n",
      "accuracy: 49.75124378109453\n",
      "epoch14 end\n",
      "Loss: 4.757305333027636\n",
      "accuracy: 51.243781094527364\n",
      "epoch15 end\n",
      "Loss: 0.920162987079064\n",
      "accuracy: 52.7363184079602\n",
      "epoch16 end\n",
      "Loss: 1.24368733684932\n",
      "accuracy: 53.233830845771145\n",
      "epoch17 end\n",
      "Loss: 1.0581895678959865\n",
      "accuracy: 53.73134328358209\n",
      "epoch18 end\n",
      "Loss: 0.5316758909197686\n",
      "accuracy: 53.233830845771145\n",
      "epoch19 end\n",
      "Loss: 3.197611190627952\n",
      "accuracy: 52.7363184079602\n",
      "epoch20 end\n",
      "Loss: 1.6042749533713354\n",
      "accuracy: 51.243781094527364\n",
      "epoch21 end\n",
      "Loss: 0.4721489738910297\n",
      "accuracy: 50.24875621890547\n",
      "epoch22 end\n",
      "Loss: 1.3413846089679256\n",
      "accuracy: 50.24875621890547\n",
      "epoch23 end\n",
      "Loss: 0.7752721846916415\n",
      "accuracy: 50.24875621890547\n",
      "epoch24 end\n",
      "Loss: 0.7162431978463171\n",
      "accuracy: 49.75124378109453\n",
      "epoch25 end\n",
      "Loss: 0.6802643151997311\n",
      "accuracy: 49.75124378109453\n",
      "epoch26 end\n",
      "Loss: 0.8029736107571163\n",
      "accuracy: 49.75124378109453\n",
      "epoch27 end\n",
      "Loss: 1.6652825421504236\n",
      "accuracy: 52.23880597014925\n",
      "epoch28 end\n",
      "Loss: 2.827292135153583\n",
      "accuracy: 49.75124378109453\n",
      "epoch29 end\n",
      "Loss: 0.7622889621474516\n",
      "accuracy: 50.24875621890547\n",
      "epoch30 end\n",
      "Loss: 0.2733965687254621\n",
      "accuracy: 50.24875621890547\n",
      "epoch31 end\n",
      "Loss: 0.6109817743707204\n",
      "accuracy: 50.24875621890547\n",
      "epoch32 end\n",
      "Loss: 1.8184868863366934\n",
      "accuracy: 50.24875621890547\n",
      "epoch33 end\n",
      "Loss: 1.9723060069688174\n",
      "accuracy: 49.75124378109453\n",
      "epoch34 end\n",
      "Loss: 0.5372554015063171\n",
      "accuracy: 50.24875621890547\n",
      "epoch35 end\n",
      "Loss: 2.7372714491387877\n",
      "accuracy: 49.75124378109453\n",
      "epoch36 end\n",
      "Loss: 0.5663120169912539\n",
      "accuracy: 49.75124378109453\n",
      "epoch37 end\n",
      "Loss: 0.3827842959493163\n",
      "accuracy: 49.75124378109453\n",
      "epoch38 end\n",
      "Loss: 0.4268102226867043\n",
      "accuracy: 49.75124378109453\n",
      "epoch39 end\n",
      "Loss: 0.5458767987654698\n",
      "accuracy: 49.75124378109453\n",
      "epoch40 end\n",
      "Loss: 0.953405509555046\n",
      "accuracy: 49.75124378109453\n",
      "epoch41 end\n",
      "Loss: 1.6564222926373666\n",
      "accuracy: 49.75124378109453\n",
      "epoch42 end\n",
      "Loss: 0.7723594932040563\n",
      "accuracy: 50.74626865671642\n",
      "epoch43 end\n",
      "Loss: 1.1402808407767542\n",
      "accuracy: 50.24875621890547\n",
      "epoch44 end\n",
      "Loss: 0.7580100918736256\n",
      "accuracy: 49.75124378109453\n",
      "epoch45 end\n",
      "Loss: 0.7549003969818325\n",
      "accuracy: 49.75124378109453\n",
      "epoch46 end\n",
      "Loss: 1.4390566725812364\n",
      "accuracy: 49.75124378109453\n",
      "epoch47 end\n",
      "Loss: 0.4185126485613771\n",
      "accuracy: 49.75124378109453\n",
      "epoch48 end\n",
      "Loss: 0.6049380222961812\n",
      "accuracy: 50.24875621890547\n",
      "epoch49 end\n",
      "Loss: 0.4727868454761694\n",
      "accuracy: 50.74626865671642\n",
      "epoch50 end\n",
      "Loss: 1.2235444187797913\n",
      "accuracy: 49.75124378109453\n",
      "epoch51 end\n",
      "Loss: 1.2285957774046115\n",
      "accuracy: 50.24875621890547\n",
      "epoch52 end\n",
      "Loss: 2.7648040142431363\n",
      "accuracy: 49.25373134328358\n",
      "epoch53 end\n",
      "Loss: 1.4322352087661714\n",
      "accuracy: 49.75124378109453\n",
      "epoch54 end\n",
      "Loss: 1.307548095134894\n",
      "accuracy: 49.75124378109453\n",
      "epoch55 end\n",
      "Loss: 0.9063938841353549\n",
      "accuracy: 50.24875621890547\n",
      "epoch56 end\n",
      "Loss: 0.9507197919836905\n",
      "accuracy: 50.24875621890547\n",
      "epoch57 end\n",
      "Loss: 0.6928597717042039\n",
      "accuracy: 49.75124378109453\n",
      "epoch58 end\n",
      "Loss: 0.8535487200028037\n",
      "accuracy: 50.74626865671642\n",
      "epoch59 end\n",
      "Loss: 0.5213019238607783\n",
      "accuracy: 53.73134328358209\n",
      "epoch60 end\n",
      "Loss: 1.860873181555241\n",
      "accuracy: 58.70646766169154\n",
      "epoch61 end\n",
      "Loss: 0.3374107223374128\n",
      "accuracy: 58.70646766169154\n",
      "epoch62 end\n",
      "Loss: 0.5249417574065992\n",
      "accuracy: 53.73134328358209\n",
      "epoch63 end\n",
      "Loss: 0.8139993779560143\n",
      "accuracy: 63.681592039801\n",
      "epoch64 end\n",
      "Loss: 0.5003020031520922\n",
      "accuracy: 66.16915422885572\n",
      "epoch65 end\n",
      "Loss: 0.6806033651189153\n",
      "accuracy: 66.16915422885572\n",
      "epoch66 end\n",
      "Loss: 0.22876479096457544\n",
      "accuracy: 65.17412935323384\n",
      "epoch67 end\n",
      "Loss: 0.8738641847872332\n",
      "accuracy: 55.72139303482587\n",
      "epoch68 end\n",
      "Loss: 1.6415370951504744\n",
      "accuracy: 57.21393034825871\n",
      "epoch69 end\n",
      "Loss: 1.0624094733140597\n",
      "accuracy: 49.75124378109453\n",
      "epoch70 end\n",
      "Loss: 0.6547549708402066\n",
      "accuracy: 52.7363184079602\n",
      "epoch71 end\n",
      "Loss: 0.24945447702856605\n",
      "accuracy: 53.73134328358209\n",
      "epoch72 end\n",
      "Loss: 0.5365786894901086\n",
      "accuracy: 50.24875621890547\n",
      "epoch73 end\n",
      "Loss: 0.2536700524232778\n",
      "accuracy: 50.24875621890547\n",
      "epoch74 end\n",
      "Loss: 0.9742182360909497\n",
      "accuracy: 50.24875621890547\n",
      "epoch75 end\n",
      "Loss: 0.554160256848459\n",
      "accuracy: 49.75124378109453\n",
      "epoch76 end\n",
      "Loss: 0.20550519790015404\n",
      "accuracy: 49.75124378109453\n",
      "epoch77 end\n",
      "Loss: 0.6721858606253553\n",
      "accuracy: 49.75124378109453\n",
      "epoch78 end\n",
      "Loss: 0.5206967994348566\n",
      "accuracy: 50.24875621890547\n",
      "epoch79 end\n",
      "Loss: 1.0080478375998865\n",
      "accuracy: 51.74129353233831\n",
      "epoch80 end\n",
      "Loss: 1.1212166751897055\n",
      "accuracy: 49.75124378109453\n",
      "epoch81 end\n",
      "Loss: 1.342163290847064\n",
      "accuracy: 50.74626865671642\n",
      "epoch82 end\n",
      "Loss: 0.20987045881873218\n",
      "accuracy: 49.75124378109453\n",
      "epoch83 end\n",
      "Loss: 0.5478462718958326\n",
      "accuracy: 49.25373134328358\n",
      "epoch84 end\n",
      "Loss: 0.8422662145498719\n",
      "accuracy: 49.75124378109453\n",
      "epoch85 end\n",
      "Loss: 0.8283028239821325\n",
      "accuracy: 49.75124378109453\n",
      "epoch86 end\n",
      "Loss: 0.3404386448020208\n",
      "accuracy: 49.75124378109453\n",
      "epoch87 end\n",
      "Loss: 0.8568775711082219\n",
      "accuracy: 49.75124378109453\n",
      "epoch88 end\n",
      "Loss: 0.5959116180905163\n",
      "accuracy: 49.75124378109453\n",
      "epoch89 end\n",
      "Loss: 0.6943047596626786\n",
      "accuracy: 49.75124378109453\n",
      "epoch90 end\n",
      "Loss: 0.951162402068117\n",
      "accuracy: 49.75124378109453\n",
      "epoch91 end\n",
      "Loss: 0.4794410735745426\n",
      "accuracy: 49.75124378109453\n",
      "epoch92 end\n",
      "Loss: 0.2003113596519405\n",
      "accuracy: 49.75124378109453\n",
      "epoch93 end\n",
      "Loss: 1.8038895305515588\n",
      "accuracy: 49.75124378109453\n",
      "epoch94 end\n",
      "Loss: 0.9014545474141566\n",
      "accuracy: 49.75124378109453\n",
      "epoch95 end\n",
      "Loss: 0.9411177215562235\n",
      "accuracy: 49.75124378109453\n",
      "epoch96 end\n",
      "Loss: 0.4167369776642717\n",
      "accuracy: 49.75124378109453\n",
      "epoch97 end\n",
      "Loss: 0.4015558033975565\n",
      "accuracy: 49.75124378109453\n",
      "epoch98 end\n",
      "Loss: 0.180761922562277\n",
      "accuracy: 49.75124378109453\n",
      "epoch99 end\n",
      "Loss: 0.6552203664418303\n",
      "accuracy: 49.75124378109453\n",
      "epoch100 end\n",
      "Loss: 0.4328630640516731\n",
      "accuracy: 49.75124378109453\n",
      "epoch101 end\n",
      "Loss: 0.7416143164782947\n",
      "accuracy: 49.75124378109453\n",
      "epoch102 end\n",
      "Loss: 0.7187170338889397\n",
      "accuracy: 49.75124378109453\n",
      "epoch103 end\n",
      "Loss: 0.5796230014508945\n",
      "accuracy: 49.75124378109453\n",
      "epoch104 end\n",
      "Loss: 1.3122443112227777\n",
      "accuracy: 49.75124378109453\n",
      "epoch105 end\n",
      "Loss: 0.5166394351709191\n",
      "accuracy: 49.75124378109453\n",
      "epoch106 end\n",
      "Loss: 0.6365341945992985\n",
      "accuracy: 49.75124378109453\n",
      "epoch107 end\n",
      "Loss: 0.16025275109321413\n",
      "accuracy: 49.75124378109453\n",
      "epoch108 end\n",
      "Loss: 0.75385057360869\n",
      "accuracy: 49.75124378109453\n",
      "epoch109 end\n",
      "Loss: 0.2786852054187745\n",
      "accuracy: 49.75124378109453\n",
      "epoch110 end\n",
      "Loss: 0.5942275090231584\n",
      "accuracy: 49.75124378109453\n",
      "epoch111 end\n",
      "Loss: 0.485079232112822\n",
      "accuracy: 49.75124378109453\n",
      "epoch112 end\n",
      "Loss: 0.40740384920904543\n",
      "accuracy: 49.75124378109453\n",
      "epoch113 end\n",
      "Loss: 1.3563756606309163\n",
      "accuracy: 49.75124378109453\n",
      "epoch114 end\n",
      "Loss: 0.3361077176366618\n",
      "accuracy: 49.75124378109453\n",
      "epoch115 end\n",
      "Loss: 0.40548920488363904\n",
      "accuracy: 49.75124378109453\n",
      "epoch116 end\n",
      "Loss: 0.33139933035869235\n",
      "accuracy: 49.75124378109453\n",
      "epoch117 end\n",
      "Loss: 0.5521920599905062\n",
      "accuracy: 49.75124378109453\n",
      "epoch118 end\n",
      "Loss: 0.573386404551768\n",
      "accuracy: 49.75124378109453\n",
      "epoch119 end\n",
      "Loss: 0.9013915771260503\n",
      "accuracy: 49.75124378109453\n",
      "epoch120 end\n",
      "Loss: 0.7924019260168007\n",
      "accuracy: 49.75124378109453\n",
      "epoch121 end\n",
      "Loss: 0.3128678422778493\n",
      "accuracy: 49.75124378109453\n",
      "epoch122 end\n",
      "Loss: 0.4129133703251558\n",
      "accuracy: 49.75124378109453\n",
      "epoch123 end\n",
      "Loss: 0.17553270110523328\n",
      "accuracy: 49.75124378109453\n",
      "epoch124 end\n",
      "Loss: 0.234552683243259\n",
      "accuracy: 49.75124378109453\n",
      "epoch125 end\n",
      "Loss: 0.6461439268074514\n",
      "accuracy: 49.75124378109453\n",
      "epoch126 end\n",
      "Loss: 0.27023709278850705\n",
      "accuracy: 49.75124378109453\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch127 end\n",
      "Loss: 0.7045971776268879\n",
      "accuracy: 49.75124378109453\n",
      "epoch128 end\n",
      "Loss: 0.21945500490010517\n",
      "accuracy: 49.75124378109453\n",
      "epoch129 end\n",
      "Loss: 0.5984594954311404\n",
      "accuracy: 49.75124378109453\n",
      "epoch130 end\n",
      "Loss: 0.15164159907355318\n",
      "accuracy: 49.75124378109453\n",
      "epoch131 end\n",
      "Loss: 0.53532714924917\n",
      "accuracy: 49.75124378109453\n",
      "epoch132 end\n",
      "Loss: 0.7060427610305109\n",
      "accuracy: 49.75124378109453\n",
      "epoch133 end\n",
      "Loss: 0.9952064891928453\n",
      "accuracy: 49.75124378109453\n",
      "epoch134 end\n",
      "Loss: 1.0997997815266414\n",
      "accuracy: 49.75124378109453\n",
      "epoch135 end\n",
      "Loss: 0.20731707667766827\n",
      "accuracy: 49.75124378109453\n",
      "epoch136 end\n",
      "Loss: 0.2531787303512555\n",
      "accuracy: 49.75124378109453\n",
      "epoch137 end\n",
      "Loss: 0.2856548564158001\n",
      "accuracy: 49.75124378109453\n",
      "epoch138 end\n",
      "Loss: 0.17996241291606221\n",
      "accuracy: 49.75124378109453\n",
      "epoch139 end\n",
      "Loss: 1.6397169301495755\n",
      "accuracy: 49.75124378109453\n",
      "epoch140 end\n",
      "Loss: 0.17570478912796833\n",
      "accuracy: 49.75124378109453\n",
      "epoch141 end\n",
      "Loss: 0.20025440462698496\n",
      "accuracy: 49.75124378109453\n",
      "epoch142 end\n",
      "Loss: 1.195212485592838\n",
      "accuracy: 49.75124378109453\n",
      "epoch143 end\n",
      "Loss: 0.6743924362763775\n",
      "accuracy: 49.75124378109453\n",
      "epoch144 end\n",
      "Loss: 0.5217788583090293\n",
      "accuracy: 49.75124378109453\n",
      "epoch145 end\n",
      "Loss: 1.4287853979761844\n",
      "accuracy: 49.75124378109453\n",
      "epoch146 end\n",
      "Loss: 0.1178346841842491\n",
      "accuracy: 49.75124378109453\n",
      "epoch147 end\n",
      "Loss: 0.38791678945088093\n",
      "accuracy: 49.75124378109453\n",
      "epoch148 end\n",
      "Loss: 0.7232499346910665\n",
      "accuracy: 49.75124378109453\n",
      "epoch149 end\n",
      "Loss: 0.43315783305049543\n",
      "accuracy: 49.75124378109453\n",
      "epoch150 end\n",
      "Loss: 0.6955813466842518\n",
      "accuracy: 49.75124378109453\n",
      "epoch151 end\n",
      "Loss: 0.6531987671930115\n",
      "accuracy: 49.75124378109453\n",
      "epoch152 end\n",
      "Loss: 0.751947320640176\n",
      "accuracy: 49.75124378109453\n",
      "epoch153 end\n",
      "Loss: 0.2981133962136501\n",
      "accuracy: 49.75124378109453\n",
      "epoch154 end\n",
      "Loss: 0.39030979960315265\n",
      "accuracy: 49.75124378109453\n",
      "epoch155 end\n",
      "Loss: 0.7461743158964322\n",
      "accuracy: 49.75124378109453\n",
      "epoch156 end\n",
      "Loss: 0.24715912211446017\n",
      "accuracy: 49.75124378109453\n",
      "epoch157 end\n",
      "Loss: 0.329133852934428\n",
      "accuracy: 49.75124378109453\n",
      "epoch158 end\n",
      "Loss: 0.41513137823293045\n",
      "accuracy: 49.75124378109453\n",
      "epoch159 end\n",
      "Loss: 0.6801829680112913\n",
      "accuracy: 49.75124378109453\n",
      "epoch160 end\n",
      "Loss: 0.35813547128503476\n",
      "accuracy: 49.75124378109453\n",
      "epoch161 end\n",
      "Loss: 0.2962198285914267\n",
      "accuracy: 49.75124378109453\n",
      "epoch162 end\n",
      "Loss: 0.11304477943448007\n",
      "accuracy: 49.75124378109453\n",
      "epoch163 end\n",
      "Loss: 0.4452474107203061\n",
      "accuracy: 49.75124378109453\n",
      "epoch164 end\n",
      "Loss: 0.6418835058401939\n",
      "accuracy: 49.75124378109453\n",
      "epoch165 end\n",
      "Loss: 0.7784576914744241\n",
      "accuracy: 49.75124378109453\n",
      "epoch166 end\n",
      "Loss: 0.8329846859191609\n",
      "accuracy: 49.75124378109453\n",
      "epoch167 end\n",
      "Loss: 0.2112411739548667\n",
      "accuracy: 49.75124378109453\n",
      "epoch168 end\n",
      "Loss: 0.13367450405726505\n",
      "accuracy: 49.75124378109453\n",
      "epoch169 end\n",
      "Loss: 1.031401361872176\n",
      "accuracy: 49.75124378109453\n",
      "epoch170 end\n",
      "Loss: 1.040597187111624\n",
      "accuracy: 49.75124378109453\n",
      "epoch171 end\n",
      "Loss: 0.1376559149887072\n",
      "accuracy: 49.75124378109453\n",
      "epoch172 end\n",
      "Loss: 0.6252648584103315\n",
      "accuracy: 49.75124378109453\n",
      "epoch173 end\n",
      "Loss: 0.10646552142412788\n",
      "accuracy: 49.75124378109453\n",
      "epoch174 end\n",
      "Loss: 0.23571294607214116\n",
      "accuracy: 49.75124378109453\n",
      "epoch175 end\n",
      "Loss: 0.3480847047314549\n",
      "accuracy: 49.75124378109453\n",
      "epoch176 end\n",
      "Loss: 0.4923826814160394\n",
      "accuracy: 49.75124378109453\n",
      "epoch177 end\n",
      "Loss: 0.7275160609788585\n",
      "accuracy: 49.75124378109453\n",
      "epoch178 end\n",
      "Loss: 0.7406763382916807\n",
      "accuracy: 49.75124378109453\n",
      "epoch179 end\n",
      "Loss: 0.3637685059834245\n",
      "accuracy: 49.75124378109453\n",
      "epoch180 end\n",
      "Loss: 0.4217622178104684\n",
      "accuracy: 49.75124378109453\n",
      "epoch181 end\n",
      "Loss: 0.17844982907707077\n",
      "accuracy: 49.75124378109453\n",
      "epoch182 end\n",
      "Loss: 0.4252959071272057\n",
      "accuracy: 49.75124378109453\n",
      "epoch183 end\n",
      "Loss: 0.7710812565278097\n",
      "accuracy: 49.75124378109453\n",
      "epoch184 end\n",
      "Loss: 0.3486447505227682\n",
      "accuracy: 49.75124378109453\n",
      "epoch185 end\n",
      "Loss: 0.23931546293471956\n",
      "accuracy: 49.75124378109453\n",
      "epoch186 end\n",
      "Loss: 0.2536591462476877\n",
      "accuracy: 49.75124378109453\n",
      "epoch187 end\n",
      "Loss: 0.633234897121768\n",
      "accuracy: 49.75124378109453\n",
      "epoch188 end\n",
      "Loss: 0.30448578309275204\n",
      "accuracy: 49.75124378109453\n",
      "epoch189 end\n",
      "Loss: 0.5571974901311949\n",
      "accuracy: 49.75124378109453\n",
      "epoch190 end\n",
      "Loss: 0.8531003286873338\n",
      "accuracy: 49.75124378109453\n",
      "epoch191 end\n",
      "Loss: 1.646194207488671\n",
      "accuracy: 49.75124378109453\n",
      "epoch192 end\n",
      "Loss: 0.1905655305520703\n",
      "accuracy: 49.75124378109453\n",
      "epoch193 end\n",
      "Loss: 0.2721541938165741\n",
      "accuracy: 49.75124378109453\n",
      "epoch194 end\n",
      "Loss: 0.4706223374395108\n",
      "accuracy: 49.75124378109453\n",
      "epoch195 end\n",
      "Loss: 0.38799142551263416\n",
      "accuracy: 49.75124378109453\n",
      "epoch196 end\n",
      "Loss: 0.4451780949097054\n",
      "accuracy: 49.75124378109453\n",
      "epoch197 end\n",
      "Loss: 0.2866371931191266\n",
      "accuracy: 49.75124378109453\n",
      "epoch198 end\n",
      "Loss: 0.31979139062862794\n",
      "accuracy: 49.75124378109453\n",
      "epoch199 end\n",
      "Loss: 0.11447889314012523\n",
      "accuracy: 49.75124378109453\n",
      "epoch200 end\n",
      "Loss: 0.09243771507950452\n",
      "accuracy: 49.75124378109453\n",
      "epoch201 end\n",
      "Loss: 0.7606650492791693\n",
      "accuracy: 49.75124378109453\n",
      "epoch202 end\n",
      "Loss: 0.563245974291961\n",
      "accuracy: 49.75124378109453\n",
      "epoch203 end\n",
      "Loss: 0.39692143573692173\n",
      "accuracy: 49.75124378109453\n",
      "epoch204 end\n",
      "Loss: 0.39116172852551245\n",
      "accuracy: 49.75124378109453\n",
      "epoch205 end\n",
      "Loss: 1.0173029878669186\n",
      "accuracy: 49.75124378109453\n",
      "epoch206 end\n",
      "Loss: 0.9558196284818845\n",
      "accuracy: 49.75124378109453\n",
      "epoch207 end\n",
      "Loss: 0.13670724683685898\n",
      "accuracy: 49.75124378109453\n",
      "epoch208 end\n",
      "Loss: 0.5108584076945812\n",
      "accuracy: 49.75124378109453\n",
      "epoch209 end\n",
      "Loss: 0.13424669051130428\n",
      "accuracy: 49.75124378109453\n",
      "epoch210 end\n",
      "Loss: 0.2758211316203852\n",
      "accuracy: 49.75124378109453\n",
      "epoch211 end\n",
      "Loss: 0.11138135415837769\n",
      "accuracy: 49.75124378109453\n",
      "epoch212 end\n",
      "Loss: 0.21552668963906307\n",
      "accuracy: 49.75124378109453\n",
      "epoch213 end\n",
      "Loss: 0.3792561637374244\n",
      "accuracy: 49.75124378109453\n",
      "epoch214 end\n",
      "Loss: 0.08973516076208168\n",
      "accuracy: 49.75124378109453\n",
      "epoch215 end\n",
      "Loss: 0.9758468219520475\n",
      "accuracy: 49.75124378109453\n",
      "epoch216 end\n",
      "Loss: 0.2442684299938201\n",
      "accuracy: 49.75124378109453\n",
      "epoch217 end\n",
      "Loss: 0.7430351721690085\n",
      "accuracy: 49.75124378109453\n",
      "epoch218 end\n",
      "Loss: 1.5938798552543525\n",
      "accuracy: 49.75124378109453\n",
      "epoch219 end\n",
      "Loss: 0.30935543178786873\n",
      "accuracy: 49.75124378109453\n",
      "epoch220 end\n",
      "Loss: 0.21783190911070438\n",
      "accuracy: 49.75124378109453\n",
      "epoch221 end\n",
      "Loss: 0.378660385464613\n",
      "accuracy: 49.75124378109453\n",
      "epoch222 end\n",
      "Loss: 0.6312246349079779\n",
      "accuracy: 49.75124378109453\n",
      "epoch223 end\n",
      "Loss: 0.28875922645170365\n",
      "accuracy: 49.75124378109453\n",
      "epoch224 end\n",
      "Loss: 0.2801934933042627\n",
      "accuracy: 49.75124378109453\n",
      "epoch225 end\n",
      "Loss: 0.1782830276194684\n",
      "accuracy: 49.75124378109453\n",
      "epoch226 end\n",
      "Loss: 0.19639902454721103\n",
      "accuracy: 49.75124378109453\n",
      "epoch227 end\n",
      "Loss: 0.5919565093482657\n",
      "accuracy: 49.75124378109453\n",
      "epoch228 end\n",
      "Loss: 0.7647621941935209\n",
      "accuracy: 49.75124378109453\n",
      "epoch229 end\n",
      "Loss: 0.19925090195288025\n",
      "accuracy: 49.75124378109453\n",
      "epoch230 end\n",
      "Loss: 0.15600387539373695\n",
      "accuracy: 49.75124378109453\n",
      "epoch231 end\n",
      "Loss: 0.16974758288623643\n",
      "accuracy: 49.75124378109453\n",
      "epoch232 end\n",
      "Loss: 0.05861516407555214\n",
      "accuracy: 49.75124378109453\n",
      "epoch233 end\n",
      "Loss: 0.29897513280375165\n",
      "accuracy: 49.75124378109453\n",
      "epoch234 end\n",
      "Loss: 0.7454976522187893\n",
      "accuracy: 49.75124378109453\n",
      "epoch235 end\n",
      "Loss: 0.2760319682735658\n",
      "accuracy: 49.75124378109453\n",
      "epoch236 end\n",
      "Loss: 0.47967305540893956\n",
      "accuracy: 49.75124378109453\n",
      "epoch237 end\n",
      "Loss: 0.1929444673517265\n",
      "accuracy: 49.75124378109453\n",
      "epoch238 end\n",
      "Loss: 0.18240190601938033\n",
      "accuracy: 49.75124378109453\n",
      "epoch239 end\n",
      "Loss: 0.2617598632986624\n",
      "accuracy: 49.75124378109453\n",
      "epoch240 end\n",
      "Loss: 0.35916242206020443\n",
      "accuracy: 49.75124378109453\n",
      "epoch241 end\n",
      "Loss: 0.5595004298863455\n",
      "accuracy: 49.75124378109453\n",
      "epoch242 end\n",
      "Loss: 0.25053691132441536\n",
      "accuracy: 49.75124378109453\n",
      "epoch243 end\n",
      "Loss: 0.20511211625359893\n",
      "accuracy: 49.75124378109453\n",
      "epoch244 end\n",
      "Loss: 0.4094147394584608\n",
      "accuracy: 49.75124378109453\n",
      "epoch245 end\n",
      "Loss: 0.1361258952357174\n",
      "accuracy: 49.75124378109453\n",
      "epoch246 end\n",
      "Loss: 0.3577765514858097\n",
      "accuracy: 49.75124378109453\n",
      "epoch247 end\n",
      "Loss: 0.21183655241099464\n",
      "accuracy: 49.75124378109453\n",
      "epoch248 end\n",
      "Loss: 0.1282203302897789\n",
      "accuracy: 49.75124378109453\n",
      "epoch249 end\n",
      "Loss: 0.2642254293496169\n",
      "accuracy: 49.75124378109453\n",
      "epoch250 end\n",
      "Loss: 0.39576134346609754\n",
      "accuracy: 49.75124378109453\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch251 end\n",
      "Loss: 0.18348535833702645\n",
      "accuracy: 49.75124378109453\n",
      "epoch252 end\n",
      "Loss: 0.2430434498961974\n",
      "accuracy: 49.75124378109453\n",
      "epoch253 end\n",
      "Loss: 0.21129834569951417\n",
      "accuracy: 49.75124378109453\n",
      "epoch254 end\n",
      "Loss: 0.11296601025873745\n",
      "accuracy: 49.75124378109453\n",
      "epoch255 end\n",
      "Loss: 0.23192094960669998\n",
      "accuracy: 49.75124378109453\n",
      "epoch256 end\n",
      "Loss: 0.12279145714270587\n",
      "accuracy: 49.75124378109453\n",
      "epoch257 end\n",
      "Loss: 0.07932291470014655\n",
      "accuracy: 49.75124378109453\n",
      "epoch258 end\n",
      "Loss: 0.21561115401382142\n",
      "accuracy: 49.75124378109453\n",
      "epoch259 end\n",
      "Loss: 0.47989924627970926\n",
      "accuracy: 49.75124378109453\n",
      "epoch260 end\n",
      "Loss: 0.0498481701569183\n",
      "accuracy: 49.75124378109453\n",
      "epoch261 end\n",
      "Loss: 0.09289654916915496\n",
      "accuracy: 49.75124378109453\n",
      "epoch262 end\n",
      "Loss: 0.6771490229385767\n",
      "accuracy: 49.75124378109453\n",
      "epoch263 end\n",
      "Loss: 0.0784385466275407\n",
      "accuracy: 49.75124378109453\n",
      "epoch264 end\n",
      "Loss: 0.5324845390833075\n",
      "accuracy: 49.75124378109453\n",
      "epoch265 end\n",
      "Loss: 0.45525921397360286\n",
      "accuracy: 49.75124378109453\n",
      "epoch266 end\n",
      "Loss: 0.7870859851777108\n",
      "accuracy: 49.75124378109453\n",
      "epoch267 end\n",
      "Loss: 0.21169578302636366\n",
      "accuracy: 49.75124378109453\n",
      "epoch268 end\n",
      "Loss: 0.19510748807028397\n",
      "accuracy: 49.75124378109453\n",
      "epoch269 end\n",
      "Loss: 0.2330284750321793\n",
      "accuracy: 49.75124378109453\n",
      "epoch270 end\n",
      "Loss: 0.4144407021461838\n",
      "accuracy: 49.75124378109453\n",
      "epoch271 end\n",
      "Loss: 0.11675149132640657\n",
      "accuracy: 49.75124378109453\n",
      "epoch272 end\n",
      "Loss: 0.1868561194235352\n",
      "accuracy: 49.75124378109453\n",
      "epoch273 end\n",
      "Loss: 0.7695464970596738\n",
      "accuracy: 49.75124378109453\n",
      "epoch274 end\n",
      "Loss: 0.5688186579916816\n",
      "accuracy: 49.75124378109453\n",
      "epoch275 end\n",
      "Loss: 0.22823260232685097\n",
      "accuracy: 49.75124378109453\n",
      "epoch276 end\n",
      "Loss: 0.1315879113925043\n",
      "accuracy: 49.75124378109453\n",
      "epoch277 end\n",
      "Loss: 0.24426714726098364\n",
      "accuracy: 49.75124378109453\n",
      "epoch278 end\n",
      "Loss: 0.2407051024276619\n",
      "accuracy: 49.75124378109453\n",
      "epoch279 end\n",
      "Loss: 0.28942236012021744\n",
      "accuracy: 49.75124378109453\n",
      "epoch280 end\n",
      "Loss: 0.4206362137277061\n",
      "accuracy: 49.75124378109453\n",
      "epoch281 end\n",
      "Loss: 0.45259159565130747\n",
      "accuracy: 49.75124378109453\n",
      "epoch282 end\n",
      "Loss: 0.1600850662478903\n",
      "accuracy: 49.75124378109453\n",
      "epoch283 end\n",
      "Loss: 0.9638965892618936\n",
      "accuracy: 49.75124378109453\n",
      "epoch284 end\n",
      "Loss: 0.07162063004283095\n",
      "accuracy: 49.75124378109453\n",
      "epoch285 end\n",
      "Loss: 0.24350546871240217\n",
      "accuracy: 49.75124378109453\n",
      "epoch286 end\n",
      "Loss: 0.38163298516757316\n",
      "accuracy: 49.75124378109453\n",
      "epoch287 end\n",
      "Loss: 0.14032882347969516\n",
      "accuracy: 49.75124378109453\n",
      "epoch288 end\n",
      "Loss: 0.17230575945960416\n",
      "accuracy: 49.75124378109453\n",
      "epoch289 end\n",
      "Loss: 0.21053046158606287\n",
      "accuracy: 49.75124378109453\n",
      "epoch290 end\n",
      "Loss: 0.10448905235819975\n",
      "accuracy: 49.75124378109453\n",
      "epoch291 end\n",
      "Loss: 0.3732907218002154\n",
      "accuracy: 49.75124378109453\n",
      "epoch292 end\n",
      "Loss: 0.12246469309769414\n",
      "accuracy: 49.75124378109453\n",
      "epoch293 end\n",
      "Loss: 0.15389954362276653\n",
      "accuracy: 49.75124378109453\n",
      "epoch294 end\n",
      "Loss: 0.1450637363002417\n",
      "accuracy: 49.75124378109453\n",
      "epoch295 end\n",
      "Loss: 0.1212026048545114\n",
      "accuracy: 49.75124378109453\n",
      "epoch296 end\n",
      "Loss: 0.3753224400605572\n",
      "accuracy: 49.75124378109453\n",
      "epoch297 end\n",
      "Loss: 0.18313871364172854\n",
      "accuracy: 49.75124378109453\n",
      "epoch298 end\n",
      "Loss: 0.21350618108948832\n",
      "accuracy: 49.75124378109453\n",
      "epoch299 end\n",
      "Loss: 0.10494557717761004\n",
      "accuracy: 49.75124378109453\n",
      "epoch300 end\n",
      "Loss: 0.32039966386895113\n",
      "accuracy: 49.75124378109453\n",
      "epoch301 end\n",
      "Loss: 0.3126418081132104\n",
      "accuracy: 49.75124378109453\n",
      "epoch302 end\n",
      "Loss: 0.30218899666603116\n",
      "accuracy: 49.75124378109453\n",
      "epoch303 end\n",
      "Loss: 0.0627463312144972\n",
      "accuracy: 49.75124378109453\n",
      "epoch304 end\n",
      "Loss: 0.16619159905288206\n",
      "accuracy: 49.75124378109453\n",
      "epoch305 end\n",
      "Loss: 0.817026114528937\n",
      "accuracy: 49.75124378109453\n",
      "epoch306 end\n",
      "Loss: 0.5254769155805257\n",
      "accuracy: 49.75124378109453\n",
      "epoch307 end\n",
      "Loss: 0.7173387302477063\n",
      "accuracy: 49.75124378109453\n",
      "epoch308 end\n",
      "Loss: 0.46418999560556384\n",
      "accuracy: 49.75124378109453\n",
      "epoch309 end\n",
      "Loss: 0.3865084643701688\n",
      "accuracy: 49.75124378109453\n",
      "epoch310 end\n",
      "Loss: 0.19492026212051913\n",
      "accuracy: 49.75124378109453\n",
      "epoch311 end\n",
      "Loss: 0.6127585511825501\n",
      "accuracy: 49.75124378109453\n",
      "epoch312 end\n",
      "Loss: 0.268923935386044\n",
      "accuracy: 49.75124378109453\n",
      "epoch313 end\n",
      "Loss: 0.6123822372629344\n",
      "accuracy: 49.75124378109453\n",
      "epoch314 end\n",
      "Loss: 0.22290679977520805\n",
      "accuracy: 49.75124378109453\n",
      "epoch315 end\n",
      "Loss: 0.3253137094207938\n",
      "accuracy: 49.75124378109453\n",
      "epoch316 end\n",
      "Loss: 0.30795807735598507\n",
      "accuracy: 49.75124378109453\n",
      "epoch317 end\n",
      "Loss: 0.7977132678963417\n",
      "accuracy: 49.75124378109453\n",
      "epoch318 end\n",
      "Loss: 0.5643217281909624\n",
      "accuracy: 49.75124378109453\n",
      "epoch319 end\n",
      "Loss: 0.3886657261835721\n",
      "accuracy: 49.75124378109453\n",
      "epoch320 end\n",
      "Loss: 0.22044872225834608\n",
      "accuracy: 49.75124378109453\n",
      "epoch321 end\n",
      "Loss: 0.3295299793046048\n",
      "accuracy: 49.75124378109453\n",
      "epoch322 end\n",
      "Loss: 0.5279248783371076\n",
      "accuracy: 49.75124378109453\n",
      "epoch323 end\n",
      "Loss: 0.11578351619834903\n",
      "accuracy: 49.75124378109453\n",
      "epoch324 end\n",
      "Loss: 0.16113235893276992\n",
      "accuracy: 49.75124378109453\n",
      "epoch325 end\n",
      "Loss: 0.07149664624029035\n",
      "accuracy: 49.75124378109453\n",
      "epoch326 end\n",
      "Loss: 0.2862713400749133\n",
      "accuracy: 49.75124378109453\n",
      "epoch327 end\n",
      "Loss: 0.28057145323197513\n",
      "accuracy: 49.75124378109453\n",
      "epoch328 end\n",
      "Loss: 0.23451138057278942\n",
      "accuracy: 49.75124378109453\n",
      "epoch329 end\n",
      "Loss: 0.12876683603400696\n",
      "accuracy: 49.75124378109453\n",
      "epoch330 end\n",
      "Loss: 0.44592122990461813\n",
      "accuracy: 49.75124378109453\n",
      "epoch331 end\n",
      "Loss: 0.07791039306847755\n",
      "accuracy: 49.75124378109453\n",
      "epoch332 end\n",
      "Loss: 0.26888899341151756\n",
      "accuracy: 49.75124378109453\n",
      "epoch333 end\n",
      "Loss: 0.2631918837649082\n",
      "accuracy: 49.75124378109453\n",
      "epoch334 end\n",
      "Loss: 0.17913776377307808\n",
      "accuracy: 49.75124378109453\n",
      "epoch335 end\n",
      "Loss: 0.2928203126683692\n",
      "accuracy: 49.75124378109453\n",
      "epoch336 end\n",
      "Loss: 0.17823463674175366\n",
      "accuracy: 49.75124378109453\n",
      "epoch337 end\n",
      "Loss: 0.09531991742480068\n",
      "accuracy: 49.75124378109453\n",
      "epoch338 end\n",
      "Loss: 0.2516948022056594\n",
      "accuracy: 49.75124378109453\n",
      "epoch339 end\n",
      "Loss: 0.6325432496660766\n",
      "accuracy: 49.75124378109453\n",
      "epoch340 end\n",
      "Loss: 0.18889420422192113\n",
      "accuracy: 49.75124378109453\n",
      "epoch341 end\n",
      "Loss: 0.15632823371214477\n",
      "accuracy: 49.75124378109453\n",
      "epoch342 end\n",
      "Loss: 0.07362250763242445\n",
      "accuracy: 49.75124378109453\n",
      "epoch343 end\n",
      "Loss: 0.15911147282853205\n",
      "accuracy: 49.75124378109453\n",
      "epoch344 end\n",
      "Loss: 0.42479536079185765\n",
      "accuracy: 49.75124378109453\n",
      "epoch345 end\n",
      "Loss: 0.08024825421922924\n",
      "accuracy: 49.75124378109453\n",
      "epoch346 end\n",
      "Loss: 0.11983551575982976\n",
      "accuracy: 49.75124378109453\n",
      "epoch347 end\n",
      "Loss: 0.044884880698116504\n",
      "accuracy: 49.75124378109453\n",
      "epoch348 end\n",
      "Loss: 0.2228033794487568\n",
      "accuracy: 49.75124378109453\n",
      "epoch349 end\n",
      "Loss: 0.09001323144280146\n",
      "accuracy: 49.75124378109453\n",
      "epoch350 end\n",
      "Loss: 0.1948419656104251\n",
      "accuracy: 49.75124378109453\n",
      "epoch351 end\n",
      "Loss: 0.106566103320012\n",
      "accuracy: 49.75124378109453\n",
      "epoch352 end\n",
      "Loss: 0.2174800314983103\n",
      "accuracy: 49.75124378109453\n",
      "epoch353 end\n",
      "Loss: 0.1931462968294047\n",
      "accuracy: 49.75124378109453\n",
      "epoch354 end\n",
      "Loss: 0.2607867277171861\n",
      "accuracy: 49.75124378109453\n",
      "epoch355 end\n",
      "Loss: 0.2663311753035997\n",
      "accuracy: 49.75124378109453\n",
      "epoch356 end\n",
      "Loss: 0.19523715143167292\n",
      "accuracy: 49.75124378109453\n",
      "epoch357 end\n",
      "Loss: 0.5454667876601997\n",
      "accuracy: 49.75124378109453\n",
      "epoch358 end\n",
      "Loss: 0.2391217949817009\n",
      "accuracy: 49.75124378109453\n",
      "epoch359 end\n",
      "Loss: 0.3555675947844009\n",
      "accuracy: 49.75124378109453\n",
      "epoch360 end\n",
      "Loss: 0.15270292867245547\n",
      "accuracy: 49.75124378109453\n",
      "epoch361 end\n",
      "Loss: 0.1312296454855349\n",
      "accuracy: 49.75124378109453\n",
      "epoch362 end\n",
      "Loss: 0.24339975661552732\n",
      "accuracy: 49.75124378109453\n",
      "epoch363 end\n",
      "Loss: 0.13544907472882645\n",
      "accuracy: 49.75124378109453\n",
      "epoch364 end\n",
      "Loss: 0.3034819793807476\n",
      "accuracy: 49.75124378109453\n",
      "epoch365 end\n",
      "Loss: 0.21146014332228708\n",
      "accuracy: 49.75124378109453\n",
      "epoch366 end\n",
      "Loss: 0.20441128199874567\n",
      "accuracy: 49.75124378109453\n",
      "epoch367 end\n",
      "Loss: 0.21256880248445076\n",
      "accuracy: 49.75124378109453\n",
      "epoch368 end\n",
      "Loss: 0.3305678572561539\n",
      "accuracy: 49.75124378109453\n",
      "epoch369 end\n",
      "Loss: 0.21150189982726736\n",
      "accuracy: 49.75124378109453\n",
      "epoch370 end\n",
      "Loss: 0.33916857791507443\n",
      "accuracy: 49.75124378109453\n",
      "epoch371 end\n",
      "Loss: 0.18785329265989162\n",
      "accuracy: 49.75124378109453\n",
      "epoch372 end\n",
      "Loss: 0.14818429727840923\n",
      "accuracy: 49.75124378109453\n",
      "epoch373 end\n",
      "Loss: 0.3891159264971527\n",
      "accuracy: 49.75124378109453\n",
      "epoch374 end\n",
      "Loss: 0.1364455617957271\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 49.75124378109453\n",
      "epoch375 end\n",
      "Loss: 0.20899743177548707\n",
      "accuracy: 49.75124378109453\n",
      "epoch376 end\n",
      "Loss: 0.13611085037242415\n",
      "accuracy: 49.75124378109453\n",
      "epoch377 end\n",
      "Loss: 0.5583594915761831\n",
      "accuracy: 49.75124378109453\n",
      "epoch378 end\n",
      "Loss: 0.13730179274561066\n",
      "accuracy: 49.75124378109453\n",
      "epoch379 end\n",
      "Loss: 0.26675432401751\n",
      "accuracy: 49.75124378109453\n",
      "epoch380 end\n",
      "Loss: 0.1564695888932824\n",
      "accuracy: 49.75124378109453\n",
      "epoch381 end\n",
      "Loss: 0.31122719125893406\n",
      "accuracy: 49.75124378109453\n",
      "epoch382 end\n",
      "Loss: 0.22146187074484147\n",
      "accuracy: 49.75124378109453\n",
      "epoch383 end\n",
      "Loss: 0.109576849619094\n",
      "accuracy: 49.75124378109453\n",
      "epoch384 end\n",
      "Loss: 0.13335598060885356\n",
      "accuracy: 49.75124378109453\n",
      "epoch385 end\n",
      "Loss: 0.223686047492094\n",
      "accuracy: 49.75124378109453\n",
      "epoch386 end\n",
      "Loss: 0.17065456957862893\n",
      "accuracy: 49.75124378109453\n",
      "epoch387 end\n",
      "Loss: 0.18410352968851165\n",
      "accuracy: 49.75124378109453\n",
      "epoch388 end\n",
      "Loss: 0.3494603526296311\n",
      "accuracy: 49.75124378109453\n",
      "epoch389 end\n",
      "Loss: 0.37829051366778266\n",
      "accuracy: 49.75124378109453\n",
      "epoch390 end\n",
      "Loss: 0.14960394589466733\n",
      "accuracy: 49.75124378109453\n",
      "epoch391 end\n",
      "Loss: 0.2572562985259101\n",
      "accuracy: 49.75124378109453\n",
      "epoch392 end\n",
      "Loss: 0.5394599649860606\n",
      "accuracy: 49.75124378109453\n",
      "epoch393 end\n",
      "Loss: 0.08946660308777393\n",
      "accuracy: 49.75124378109453\n",
      "epoch394 end\n",
      "Loss: 0.24782895800297106\n",
      "accuracy: 49.75124378109453\n",
      "epoch395 end\n",
      "Loss: 0.07813260394581631\n",
      "accuracy: 49.75124378109453\n",
      "epoch396 end\n",
      "Loss: 0.1418700670348986\n",
      "accuracy: 49.75124378109453\n",
      "epoch397 end\n",
      "Loss: 0.19630670865033018\n",
      "accuracy: 49.75124378109453\n",
      "epoch398 end\n",
      "Loss: 0.25579248201066096\n",
      "accuracy: 49.75124378109453\n",
      "epoch399 end\n",
      "Loss: 0.12082381777988749\n",
      "accuracy: 49.75124378109453\n",
      "epoch400 end\n",
      "Loss: 0.17175037680435895\n",
      "accuracy: 49.75124378109453\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './record/acc_record_mb10_lr10'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-62df93428ea2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb_tr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./record/acc_record_mb10_lr10\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m     \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macc_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './record/acc_record_mb10_lr10'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "epoch_times =400\n",
    "\n",
    "load_batch = 100\n",
    "mini_batch_size = 10\n",
    "learning_rate = 10\n",
    "\n",
    "w_tr = np.random.rand(200000)\n",
    "b_tr = np.random.rand()\n",
    "\n",
    "Loss_list = []\n",
    "acc_list = []\n",
    "for _ in range(epoch_times):\n",
    "    p_trainbatch, n_trainbatch = load_train(load_batch)\n",
    "    w_, b_, Loss = training(w_tr,b_tr, p_trainbatch,n_trainbatch,learning_rate,mini_batch_size)\n",
    "    print(\"epoch\" + str(_ + 1) + \" end\")\n",
    "    print(\"Loss: \"+str(Loss))\n",
    "    accuracy = accuracy_eval( w_, b_ )\n",
    "    print(\"accuracy: \"+str(accuracy))\n",
    "    w_tr = w_\n",
    "    b_tr = b_\n",
    "    Loss_list.append(Loss)\n",
    "    acc_list.append(accuracy)\n",
    "    \n",
    "with open(\"./w_record_mb10_lr10\",\"wb\") as f:\n",
    "    pickle.dump(w_tr,f)\n",
    "    \n",
    "with open(\"./b_record_mb10_lr10\",\"wb\") as f:\n",
    "    pickle.dump(b_tr,f)\n",
    "    \n",
    "with open(\"./record/acc_record_mb10_lr10\",\"wb\") as f:\n",
    "    pickle.dump(acc_list,f)\n",
    "    \n",
    "with open(\"./record/loss_record_mb10_lr10\",\"wb\") as f:\n",
    "    pickle.dump(Loss_list,f)\n",
    "    \n",
    "plt.plot(Loss_list)\n",
    "plt.show()#Loss\n",
    "print()\n",
    "plt.figure()\n",
    "plt.plot(accuracy_list)\n",
    "plt.show()\n",
    "#accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch1 end\n",
      "Loss: 6.1410248285725535\n",
      "accuracy: 50.24875621890547\n",
      "epoch2 end\n",
      "Loss: 3.8189669891832194\n",
      "accuracy: 50.24875621890547\n",
      "epoch3 end\n",
      "Loss: 5.194769777863915\n",
      "accuracy: 49.75124378109453\n",
      "epoch4 end\n",
      "Loss: 4.638752421392416\n",
      "accuracy: 49.25373134328358\n",
      "epoch5 end\n",
      "Loss: 3.8117365955824574\n",
      "accuracy: 47.76119402985075\n",
      "epoch6 end\n",
      "Loss: 5.732019417888989\n",
      "accuracy: 48.25870646766169\n",
      "epoch7 end\n",
      "Loss: 5.562549128362698\n",
      "accuracy: 48.25870646766169\n",
      "epoch8 end\n",
      "Loss: 4.911533597160537\n",
      "accuracy: 45.27363184079602\n",
      "epoch9 end\n",
      "Loss: 4.23478955689358\n",
      "accuracy: 46.26865671641791\n",
      "epoch10 end\n",
      "Loss: 5.139934279699702\n",
      "accuracy: 45.77114427860697\n",
      "epoch11 end\n",
      "Loss: 5.309708869717889\n",
      "accuracy: 45.27363184079602\n",
      "epoch12 end\n",
      "Loss: 2.9164344340156565\n",
      "accuracy: 45.77114427860697\n",
      "epoch13 end\n",
      "Loss: 4.8941662168403575\n",
      "accuracy: 48.25870646766169\n",
      "epoch14 end\n",
      "Loss: 2.7882730272572602\n",
      "accuracy: 51.243781094527364\n",
      "epoch15 end\n",
      "Loss: 4.700228154042651\n",
      "accuracy: 50.24875621890547\n",
      "epoch16 end\n",
      "Loss: 4.287966889531041\n",
      "accuracy: 50.24875621890547\n",
      "epoch17 end\n",
      "Loss: 3.926729328939871\n",
      "accuracy: 51.74129353233831\n",
      "epoch18 end\n",
      "Loss: 4.377835994473605\n",
      "accuracy: 52.23880597014925\n",
      "epoch19 end\n",
      "Loss: 3.1073972140437873\n",
      "accuracy: 52.7363184079602\n",
      "epoch20 end\n",
      "Loss: 3.3749542296475847\n",
      "accuracy: 50.74626865671642\n",
      "epoch21 end\n",
      "Loss: 3.034841336445635\n",
      "accuracy: 53.233830845771145\n",
      "epoch22 end\n",
      "Loss: 3.4075473226045663\n",
      "accuracy: 53.73134328358209\n",
      "epoch23 end\n",
      "Loss: 2.9656498953135757\n",
      "accuracy: 53.233830845771145\n",
      "epoch24 end\n",
      "Loss: 2.5509126331227403\n",
      "accuracy: 52.23880597014925\n",
      "epoch25 end\n",
      "Loss: 4.467886854423008\n",
      "accuracy: 52.7363184079602\n",
      "epoch26 end\n",
      "Loss: 3.865290717150697\n",
      "accuracy: 53.233830845771145\n",
      "epoch27 end\n",
      "Loss: 3.874576300696523\n",
      "accuracy: 53.233830845771145\n",
      "epoch28 end\n",
      "Loss: 4.035665639035324\n",
      "accuracy: 51.74129353233831\n",
      "epoch29 end\n",
      "Loss: 3.6574124174632767\n",
      "accuracy: 51.243781094527364\n",
      "epoch30 end\n",
      "Loss: 2.8838498660447183\n",
      "accuracy: 50.74626865671642\n",
      "epoch31 end\n",
      "Loss: 4.115545542204844\n",
      "accuracy: 51.243781094527364\n",
      "epoch32 end\n",
      "Loss: 3.966672215383566\n",
      "accuracy: 51.74129353233831\n",
      "epoch33 end\n",
      "Loss: 3.219180474658819\n",
      "accuracy: 52.23880597014925\n",
      "epoch34 end\n",
      "Loss: 2.1262260548304237\n",
      "accuracy: 52.7363184079602\n",
      "epoch35 end\n",
      "Loss: 3.370787013541654\n",
      "accuracy: 53.233830845771145\n",
      "epoch36 end\n",
      "Loss: 2.7218260829298595\n",
      "accuracy: 52.7363184079602\n",
      "epoch37 end\n",
      "Loss: 3.1511739734465873\n",
      "accuracy: 52.7363184079602\n",
      "epoch38 end\n",
      "Loss: 2.5306363584799088\n",
      "accuracy: 52.7363184079602\n",
      "epoch39 end\n",
      "Loss: 3.215827444980791\n",
      "accuracy: 52.7363184079602\n",
      "epoch40 end\n",
      "Loss: 4.500592335746048\n",
      "accuracy: 53.233830845771145\n",
      "epoch41 end\n",
      "Loss: 0.8626182243958971\n",
      "accuracy: 53.233830845771145\n",
      "epoch42 end\n",
      "Loss: 2.3584515347869135\n",
      "accuracy: 54.22885572139303\n",
      "epoch43 end\n",
      "Loss: 2.20162892433866\n",
      "accuracy: 54.22885572139303\n",
      "epoch44 end\n",
      "Loss: 2.506469807313779\n",
      "accuracy: 53.73134328358209\n",
      "epoch45 end\n",
      "Loss: 1.827690153069478\n",
      "accuracy: 54.22885572139303\n",
      "epoch46 end\n",
      "Loss: 1.597339383205731\n",
      "accuracy: 53.73134328358209\n",
      "epoch47 end\n",
      "Loss: 2.8130084660338066\n",
      "accuracy: 53.233830845771145\n",
      "epoch48 end\n",
      "Loss: 3.0632120616886738\n",
      "accuracy: 53.233830845771145\n",
      "epoch49 end\n",
      "Loss: 2.1027549133722094\n",
      "accuracy: 53.233830845771145\n",
      "epoch50 end\n",
      "Loss: 1.9359662186085924\n",
      "accuracy: 52.7363184079602\n",
      "epoch51 end\n",
      "Loss: 2.2945704006986674\n",
      "accuracy: 52.7363184079602\n",
      "epoch52 end\n",
      "Loss: 3.369703773048503\n",
      "accuracy: 52.7363184079602\n",
      "epoch53 end\n",
      "Loss: 2.881004169773663\n",
      "accuracy: 52.7363184079602\n",
      "epoch54 end\n",
      "Loss: 2.458094649985256\n",
      "accuracy: 52.7363184079602\n",
      "epoch55 end\n",
      "Loss: 2.655285901742055\n",
      "accuracy: 52.7363184079602\n",
      "epoch56 end\n",
      "Loss: 2.819689640682585\n",
      "accuracy: 52.23880597014925\n",
      "epoch57 end\n",
      "Loss: 3.141553776531051\n",
      "accuracy: 52.23880597014925\n",
      "epoch58 end\n",
      "Loss: 2.284265836872605\n",
      "accuracy: 52.23880597014925\n",
      "epoch59 end\n",
      "Loss: 3.064253001251891\n",
      "accuracy: 52.23880597014925\n",
      "epoch60 end\n",
      "Loss: 1.7375304595824064\n",
      "accuracy: 52.23880597014925\n",
      "epoch61 end\n",
      "Loss: 1.656395221765297\n",
      "accuracy: 52.7363184079602\n",
      "epoch62 end\n",
      "Loss: 1.9102150555603366\n",
      "accuracy: 52.7363184079602\n",
      "epoch63 end\n",
      "Loss: 2.169378485187012\n",
      "accuracy: 52.23880597014925\n",
      "epoch64 end\n",
      "Loss: 1.7839859719901685\n",
      "accuracy: 52.23880597014925\n",
      "epoch65 end\n",
      "Loss: 2.290643219943938\n",
      "accuracy: 52.23880597014925\n",
      "epoch66 end\n",
      "Loss: 1.3022988537090407\n",
      "accuracy: 52.23880597014925\n",
      "epoch67 end\n",
      "Loss: 1.8007258404925865\n",
      "accuracy: 52.23880597014925\n",
      "epoch68 end\n",
      "Loss: 2.8485750388488795\n",
      "accuracy: 52.23880597014925\n",
      "epoch69 end\n",
      "Loss: 1.6967759446641455\n",
      "accuracy: 52.23880597014925\n",
      "epoch70 end\n",
      "Loss: 1.6940796868582026\n",
      "accuracy: 52.23880597014925\n",
      "epoch71 end\n",
      "Loss: 2.684837280302688\n",
      "accuracy: 52.23880597014925\n",
      "epoch72 end\n",
      "Loss: 3.387797903184749\n",
      "accuracy: 52.23880597014925\n",
      "epoch73 end\n",
      "Loss: 3.143105989544688\n",
      "accuracy: 52.23880597014925\n",
      "epoch74 end\n",
      "Loss: 2.342575242419022\n",
      "accuracy: 52.23880597014925\n",
      "epoch75 end\n",
      "Loss: 1.8322712454801575\n",
      "accuracy: 51.74129353233831\n",
      "epoch76 end\n",
      "Loss: 1.53554285465765\n",
      "accuracy: 51.74129353233831\n",
      "epoch77 end\n",
      "Loss: 1.4794204759052796\n",
      "accuracy: 51.74129353233831\n",
      "epoch78 end\n",
      "Loss: 1.6505682884394135\n",
      "accuracy: 51.74129353233831\n",
      "epoch79 end\n",
      "Loss: 2.9532518676935116\n",
      "accuracy: 51.243781094527364\n",
      "epoch80 end\n",
      "Loss: 2.736512424852953\n",
      "accuracy: 51.243781094527364\n",
      "epoch81 end\n",
      "Loss: 2.027892877712916\n",
      "accuracy: 51.243781094527364\n",
      "epoch82 end\n",
      "Loss: 1.7578677864699765\n",
      "accuracy: 51.243781094527364\n",
      "epoch83 end\n",
      "Loss: 1.6318552814670868\n",
      "accuracy: 51.243781094527364\n",
      "epoch84 end\n",
      "Loss: 1.982486165531331\n",
      "accuracy: 51.243781094527364\n",
      "epoch85 end\n",
      "Loss: 1.4352802359220467\n",
      "accuracy: 51.243781094527364\n",
      "epoch86 end\n",
      "Loss: 0.8673325046788424\n",
      "accuracy: 51.243781094527364\n",
      "epoch87 end\n",
      "Loss: 1.9686393942257667\n",
      "accuracy: 50.74626865671642\n",
      "epoch88 end\n",
      "Loss: 1.8362682470712577\n",
      "accuracy: 50.24875621890547\n",
      "epoch89 end\n",
      "Loss: 1.1713537666387523\n",
      "accuracy: 50.24875621890547\n",
      "epoch90 end\n",
      "Loss: 1.1570566840780534\n",
      "accuracy: 50.24875621890547\n",
      "epoch91 end\n",
      "Loss: 1.342484031848986\n",
      "accuracy: 50.24875621890547\n",
      "epoch92 end\n",
      "Loss: 2.0067892138800785\n",
      "accuracy: 50.24875621890547\n",
      "epoch93 end\n",
      "Loss: 1.8214272183960332\n",
      "accuracy: 50.24875621890547\n",
      "epoch94 end\n",
      "Loss: 1.8951390864596251\n",
      "accuracy: 50.24875621890547\n",
      "epoch95 end\n",
      "Loss: 1.9659995054959558\n",
      "accuracy: 50.24875621890547\n",
      "epoch96 end\n",
      "Loss: 2.2697440007526253\n",
      "accuracy: 50.24875621890547\n",
      "epoch97 end\n",
      "Loss: 1.7493028481097412\n",
      "accuracy: 50.24875621890547\n",
      "epoch98 end\n",
      "Loss: 2.2666321241443304\n",
      "accuracy: 50.24875621890547\n",
      "epoch99 end\n",
      "Loss: 1.091875792730006\n",
      "accuracy: 50.24875621890547\n",
      "epoch100 end\n",
      "Loss: 1.640689400005847\n",
      "accuracy: 50.24875621890547\n",
      "epoch101 end\n",
      "Loss: 1.8552145373048796\n",
      "accuracy: 50.24875621890547\n",
      "epoch102 end\n",
      "Loss: 1.4058575527121813\n",
      "accuracy: 50.24875621890547\n",
      "epoch103 end\n",
      "Loss: 1.2497027684044846\n",
      "accuracy: 50.24875621890547\n",
      "epoch104 end\n",
      "Loss: 2.8076875870921993\n",
      "accuracy: 50.24875621890547\n",
      "epoch105 end\n",
      "Loss: 1.4722673771618944\n",
      "accuracy: 50.24875621890547\n",
      "epoch106 end\n",
      "Loss: 1.9634027749247054\n",
      "accuracy: 50.24875621890547\n",
      "epoch107 end\n",
      "Loss: 1.1497215234910636\n",
      "accuracy: 50.24875621890547\n",
      "epoch108 end\n",
      "Loss: 2.3215416312433472\n",
      "accuracy: 50.24875621890547\n",
      "epoch109 end\n",
      "Loss: 1.8754164775625417\n",
      "accuracy: 50.24875621890547\n",
      "epoch110 end\n",
      "Loss: 1.7245951725280866\n",
      "accuracy: 50.24875621890547\n",
      "epoch111 end\n",
      "Loss: 1.378266133090865\n",
      "accuracy: 50.24875621890547\n",
      "epoch112 end\n",
      "Loss: 1.3943215665181512\n",
      "accuracy: 50.24875621890547\n",
      "epoch113 end\n",
      "Loss: 2.440584662028197\n",
      "accuracy: 49.75124378109453\n",
      "epoch114 end\n",
      "Loss: 2.1536021499309452\n",
      "accuracy: 49.75124378109453\n",
      "epoch115 end\n",
      "Loss: 1.5189173414677446\n",
      "accuracy: 49.75124378109453\n",
      "epoch116 end\n",
      "Loss: 1.4725239191969044\n",
      "accuracy: 49.75124378109453\n",
      "epoch117 end\n",
      "Loss: 1.7251129587417495\n",
      "accuracy: 49.75124378109453\n",
      "epoch118 end\n",
      "Loss: 1.4651205765500745\n",
      "accuracy: 49.75124378109453\n",
      "epoch119 end\n",
      "Loss: 1.6077840108615369\n",
      "accuracy: 49.75124378109453\n",
      "epoch120 end\n",
      "Loss: 1.414420069165935\n",
      "accuracy: 49.75124378109453\n",
      "epoch121 end\n",
      "Loss: 1.7108512456681861\n",
      "accuracy: 49.75124378109453\n",
      "epoch122 end\n",
      "Loss: 1.2545202618222981\n",
      "accuracy: 49.75124378109453\n",
      "epoch123 end\n",
      "Loss: 2.4758243860417766\n",
      "accuracy: 49.75124378109453\n",
      "epoch124 end\n",
      "Loss: 1.0864605078683751\n",
      "accuracy: 49.75124378109453\n",
      "epoch125 end\n",
      "Loss: 1.4832999208989002\n",
      "accuracy: 49.75124378109453\n",
      "epoch126 end\n",
      "Loss: 1.6551321888834898\n",
      "accuracy: 49.75124378109453\n",
      "epoch127 end\n",
      "Loss: 2.087273079690318\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 49.75124378109453\n",
      "epoch128 end\n",
      "Loss: 0.8923358763653073\n",
      "accuracy: 49.75124378109453\n",
      "epoch129 end\n",
      "Loss: 2.624700899745795\n",
      "accuracy: 49.75124378109453\n",
      "epoch130 end\n",
      "Loss: 1.3884146950551246\n",
      "accuracy: 49.75124378109453\n",
      "epoch131 end\n",
      "Loss: 1.0250079634111242\n",
      "accuracy: 49.75124378109453\n",
      "epoch132 end\n",
      "Loss: 2.392256010843999\n",
      "accuracy: 49.75124378109453\n",
      "epoch133 end\n",
      "Loss: 2.6794581289857784\n",
      "accuracy: 49.75124378109453\n",
      "epoch134 end\n",
      "Loss: 1.4985981835319422\n",
      "accuracy: 49.75124378109453\n",
      "epoch135 end\n",
      "Loss: 1.7727422414183251\n",
      "accuracy: 49.75124378109453\n",
      "epoch136 end\n",
      "Loss: 1.7172748825425421\n",
      "accuracy: 49.75124378109453\n",
      "epoch137 end\n",
      "Loss: 1.8849692694762914\n",
      "accuracy: 49.75124378109453\n",
      "epoch138 end\n",
      "Loss: 1.0968164154670808\n",
      "accuracy: 49.75124378109453\n",
      "epoch139 end\n",
      "Loss: 1.077427323555397\n",
      "accuracy: 49.75124378109453\n",
      "epoch140 end\n",
      "Loss: 1.214395339216899\n",
      "accuracy: 49.75124378109453\n",
      "epoch141 end\n",
      "Loss: 1.8905902736768478\n",
      "accuracy: 49.75124378109453\n",
      "epoch142 end\n",
      "Loss: 1.0172232563426384\n",
      "accuracy: 49.75124378109453\n",
      "epoch143 end\n",
      "Loss: 1.7595633780583517\n",
      "accuracy: 49.75124378109453\n",
      "epoch144 end\n",
      "Loss: 1.3238132352245733\n",
      "accuracy: 49.75124378109453\n",
      "epoch145 end\n",
      "Loss: 1.5012523051310853\n",
      "accuracy: 49.75124378109453\n",
      "epoch146 end\n",
      "Loss: 1.660428542739655\n",
      "accuracy: 49.75124378109453\n",
      "epoch147 end\n",
      "Loss: 1.0874493959015623\n",
      "accuracy: 49.75124378109453\n",
      "epoch148 end\n",
      "Loss: 1.2143204707195132\n",
      "accuracy: 49.75124378109453\n",
      "epoch149 end\n",
      "Loss: 1.5458700383703228\n",
      "accuracy: 49.75124378109453\n",
      "epoch150 end\n",
      "Loss: 1.6931123280180451\n",
      "accuracy: 49.75124378109453\n",
      "epoch151 end\n",
      "Loss: 1.276770463588597\n",
      "accuracy: 49.75124378109453\n",
      "epoch152 end\n",
      "Loss: 1.9325032926324526\n",
      "accuracy: 49.75124378109453\n",
      "epoch153 end\n",
      "Loss: 1.2200396556033206\n",
      "accuracy: 49.75124378109453\n",
      "epoch154 end\n",
      "Loss: 1.4617814249767958\n",
      "accuracy: 49.75124378109453\n",
      "epoch155 end\n",
      "Loss: 1.0365629634575546\n",
      "accuracy: 49.75124378109453\n",
      "epoch156 end\n",
      "Loss: 1.3139468890436359\n",
      "accuracy: 49.75124378109453\n",
      "epoch157 end\n",
      "Loss: 1.2142341779600645\n",
      "accuracy: 49.75124378109453\n",
      "epoch158 end\n",
      "Loss: 1.571640506922145\n",
      "accuracy: 49.75124378109453\n",
      "epoch159 end\n",
      "Loss: 1.1274075094582918\n",
      "accuracy: 49.75124378109453\n",
      "epoch160 end\n",
      "Loss: 1.2066210200512897\n",
      "accuracy: 49.75124378109453\n",
      "epoch161 end\n",
      "Loss: 1.2915115936272792\n",
      "accuracy: 49.75124378109453\n",
      "epoch162 end\n",
      "Loss: 1.0899497712992388\n",
      "accuracy: 49.75124378109453\n",
      "epoch163 end\n",
      "Loss: 1.8855650173675018\n",
      "accuracy: 49.75124378109453\n",
      "epoch164 end\n",
      "Loss: 1.293247271304211\n",
      "accuracy: 49.75124378109453\n",
      "epoch165 end\n",
      "Loss: 0.9874976603377743\n",
      "accuracy: 49.75124378109453\n",
      "epoch166 end\n",
      "Loss: 1.7711435013231844\n",
      "accuracy: 49.75124378109453\n",
      "epoch167 end\n",
      "Loss: 1.530341319397005\n",
      "accuracy: 49.75124378109453\n",
      "epoch168 end\n",
      "Loss: 1.3107542313518612\n",
      "accuracy: 49.75124378109453\n",
      "epoch169 end\n",
      "Loss: 0.9361468555181403\n",
      "accuracy: 49.75124378109453\n",
      "epoch170 end\n",
      "Loss: 0.8981363339107995\n",
      "accuracy: 49.75124378109453\n",
      "epoch171 end\n",
      "Loss: 1.0868958104188304\n",
      "accuracy: 49.75124378109453\n",
      "epoch172 end\n",
      "Loss: 1.6678189886499544\n",
      "accuracy: 49.75124378109453\n",
      "epoch173 end\n",
      "Loss: 1.7249465963546697\n",
      "accuracy: 49.75124378109453\n",
      "epoch174 end\n",
      "Loss: 1.6665759472456472\n",
      "accuracy: 49.75124378109453\n",
      "epoch175 end\n",
      "Loss: 1.0715284707253483\n",
      "accuracy: 49.75124378109453\n",
      "epoch176 end\n",
      "Loss: 1.9628519956544337\n",
      "accuracy: 49.75124378109453\n",
      "epoch177 end\n",
      "Loss: 1.535298237026881\n",
      "accuracy: 49.75124378109453\n",
      "epoch178 end\n",
      "Loss: 1.3742220556792533\n",
      "accuracy: 49.75124378109453\n",
      "epoch179 end\n",
      "Loss: 0.8836030409948965\n",
      "accuracy: 49.75124378109453\n",
      "epoch180 end\n",
      "Loss: 1.6790692159712362\n",
      "accuracy: 49.75124378109453\n",
      "epoch181 end\n",
      "Loss: 1.1670271743661986\n",
      "accuracy: 49.75124378109453\n",
      "epoch182 end\n",
      "Loss: 1.265349979217715\n",
      "accuracy: 49.75124378109453\n",
      "epoch183 end\n",
      "Loss: 1.733242960903853\n",
      "accuracy: 49.75124378109453\n",
      "epoch184 end\n",
      "Loss: 1.2490281878899772\n",
      "accuracy: 49.75124378109453\n",
      "epoch185 end\n",
      "Loss: 1.7177029092475615\n",
      "accuracy: 49.75124378109453\n",
      "epoch186 end\n",
      "Loss: 1.0336341621158707\n",
      "accuracy: 49.75124378109453\n",
      "epoch187 end\n",
      "Loss: 1.1775803939769205\n",
      "accuracy: 49.75124378109453\n",
      "epoch188 end\n",
      "Loss: 1.5996097708178814\n",
      "accuracy: 49.75124378109453\n",
      "epoch189 end\n",
      "Loss: 1.8352027123644497\n",
      "accuracy: 49.75124378109453\n",
      "epoch190 end\n",
      "Loss: 1.5859843640494182\n",
      "accuracy: 49.75124378109453\n",
      "epoch191 end\n",
      "Loss: 1.4642575208004447\n",
      "accuracy: 49.75124378109453\n",
      "epoch192 end\n",
      "Loss: 1.0336665504227698\n",
      "accuracy: 49.75124378109453\n",
      "epoch193 end\n",
      "Loss: 1.267781914444441\n",
      "accuracy: 49.75124378109453\n",
      "epoch194 end\n",
      "Loss: 1.6677685103087243\n",
      "accuracy: 49.75124378109453\n",
      "epoch195 end\n",
      "Loss: 1.1360703002993424\n",
      "accuracy: 49.75124378109453\n",
      "epoch196 end\n",
      "Loss: 1.0516997981475678\n",
      "accuracy: 49.75124378109453\n",
      "epoch197 end\n",
      "Loss: 1.1532973637908706\n",
      "accuracy: 49.75124378109453\n",
      "epoch198 end\n",
      "Loss: 1.5530435633812902\n",
      "accuracy: 49.75124378109453\n",
      "epoch199 end\n",
      "Loss: 0.5968192471007443\n",
      "accuracy: 49.75124378109453\n",
      "epoch200 end\n",
      "Loss: 1.106895015725426\n",
      "accuracy: 49.75124378109453\n",
      "epoch201 end\n",
      "Loss: 1.7781098008818188\n",
      "accuracy: 49.75124378109453\n",
      "epoch202 end\n",
      "Loss: 0.8481654516071182\n",
      "accuracy: 49.75124378109453\n",
      "epoch203 end\n",
      "Loss: 1.7219696935247035\n",
      "accuracy: 49.75124378109453\n",
      "epoch204 end\n",
      "Loss: 0.8617556911007952\n",
      "accuracy: 49.75124378109453\n",
      "epoch205 end\n",
      "Loss: 1.202358826147924\n",
      "accuracy: 49.75124378109453\n",
      "epoch206 end\n",
      "Loss: 1.430618304165496\n",
      "accuracy: 49.75124378109453\n",
      "epoch207 end\n",
      "Loss: 1.4616813179482593\n",
      "accuracy: 49.75124378109453\n",
      "epoch208 end\n",
      "Loss: 1.1201168798408068\n",
      "accuracy: 49.75124378109453\n",
      "epoch209 end\n",
      "Loss: 0.5205974559503058\n",
      "accuracy: 49.75124378109453\n",
      "epoch210 end\n",
      "Loss: 1.0828403791456809\n",
      "accuracy: 49.75124378109453\n",
      "epoch211 end\n",
      "Loss: 1.9595122392031634\n",
      "accuracy: 49.75124378109453\n",
      "epoch212 end\n",
      "Loss: 1.9129217715833078\n",
      "accuracy: 49.75124378109453\n",
      "epoch213 end\n",
      "Loss: 1.1667374962124755\n",
      "accuracy: 49.75124378109453\n",
      "epoch214 end\n",
      "Loss: 1.4263114263236025\n",
      "accuracy: 49.75124378109453\n",
      "epoch215 end\n",
      "Loss: 1.8435170358373378\n",
      "accuracy: 49.75124378109453\n",
      "epoch216 end\n",
      "Loss: 1.4372546435967444\n",
      "accuracy: 49.75124378109453\n",
      "epoch217 end\n",
      "Loss: 1.5874166229500621\n",
      "accuracy: 49.75124378109453\n",
      "epoch218 end\n",
      "Loss: 0.5709682145179216\n",
      "accuracy: 49.75124378109453\n",
      "epoch219 end\n",
      "Loss: 1.5367973977203737\n",
      "accuracy: 49.75124378109453\n",
      "epoch220 end\n",
      "Loss: 2.130773334335041\n",
      "accuracy: 49.75124378109453\n",
      "epoch221 end\n",
      "Loss: 1.3457667361812427\n",
      "accuracy: 49.75124378109453\n",
      "epoch222 end\n",
      "Loss: 1.2918240385336777\n",
      "accuracy: 49.75124378109453\n",
      "epoch223 end\n",
      "Loss: 1.7956541542112776\n",
      "accuracy: 49.75124378109453\n",
      "epoch224 end\n",
      "Loss: 1.3555916618846882\n",
      "accuracy: 49.75124378109453\n",
      "epoch225 end\n",
      "Loss: 1.9131482206066648\n",
      "accuracy: 49.75124378109453\n",
      "epoch226 end\n",
      "Loss: 1.0068856039833423\n",
      "accuracy: 49.75124378109453\n",
      "epoch227 end\n",
      "Loss: 1.3186440176155565\n",
      "accuracy: 49.75124378109453\n",
      "epoch228 end\n",
      "Loss: 0.6247325485750856\n",
      "accuracy: 49.75124378109453\n",
      "epoch229 end\n",
      "Loss: 0.9713516143923658\n",
      "accuracy: 49.75124378109453\n",
      "epoch230 end\n",
      "Loss: 1.3511046292584978\n",
      "accuracy: 49.75124378109453\n",
      "epoch231 end\n",
      "Loss: 1.6639184995839917\n",
      "accuracy: 49.75124378109453\n",
      "epoch232 end\n",
      "Loss: 1.1809508278439997\n",
      "accuracy: 49.75124378109453\n",
      "epoch233 end\n",
      "Loss: 1.7711397972546374\n",
      "accuracy: 49.75124378109453\n",
      "epoch234 end\n",
      "Loss: 1.6966058124619408\n",
      "accuracy: 49.75124378109453\n",
      "epoch235 end\n",
      "Loss: 0.6736744228011358\n",
      "accuracy: 49.75124378109453\n",
      "epoch236 end\n",
      "Loss: 1.3303723116072927\n",
      "accuracy: 49.75124378109453\n",
      "epoch237 end\n",
      "Loss: 1.4816050067730513\n",
      "accuracy: 49.75124378109453\n",
      "epoch238 end\n",
      "Loss: 1.1193119801541243\n",
      "accuracy: 49.75124378109453\n",
      "epoch239 end\n",
      "Loss: 1.3687335457819712\n",
      "accuracy: 49.75124378109453\n",
      "epoch240 end\n",
      "Loss: 0.9991256555556912\n",
      "accuracy: 49.75124378109453\n",
      "epoch241 end\n",
      "Loss: 1.1852079238663946\n",
      "accuracy: 49.75124378109453\n",
      "epoch242 end\n",
      "Loss: 1.4359616506083586\n",
      "accuracy: 49.75124378109453\n",
      "epoch243 end\n",
      "Loss: 1.2936759916732532\n",
      "accuracy: 49.75124378109453\n",
      "epoch244 end\n",
      "Loss: 0.7638736433740512\n",
      "accuracy: 49.75124378109453\n",
      "epoch245 end\n",
      "Loss: 1.2760380660004713\n",
      "accuracy: 49.75124378109453\n",
      "epoch246 end\n",
      "Loss: 1.2741369836675138\n",
      "accuracy: 49.75124378109453\n",
      "epoch247 end\n",
      "Loss: 1.6341085433252014\n",
      "accuracy: 49.75124378109453\n",
      "epoch248 end\n",
      "Loss: 0.6831481623109095\n",
      "accuracy: 49.75124378109453\n",
      "epoch249 end\n",
      "Loss: 0.7697017141491078\n",
      "accuracy: 49.75124378109453\n",
      "epoch250 end\n",
      "Loss: 1.2512108012466812\n",
      "accuracy: 49.75124378109453\n",
      "epoch251 end\n",
      "Loss: 0.7388204711713509\n",
      "accuracy: 49.75124378109453\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch252 end\n",
      "Loss: 0.8033317569214258\n",
      "accuracy: 49.75124378109453\n",
      "epoch253 end\n",
      "Loss: 0.9575658583256701\n",
      "accuracy: 49.75124378109453\n",
      "epoch254 end\n",
      "Loss: 1.5153405083627884\n",
      "accuracy: 49.75124378109453\n",
      "epoch255 end\n",
      "Loss: 2.0014546826317825\n",
      "accuracy: 49.75124378109453\n",
      "epoch256 end\n",
      "Loss: 1.4638583076809868\n",
      "accuracy: 49.75124378109453\n",
      "epoch257 end\n",
      "Loss: 1.0180105496538836\n",
      "accuracy: 49.75124378109453\n",
      "epoch258 end\n",
      "Loss: 0.7575365760949954\n",
      "accuracy: 49.75124378109453\n",
      "epoch259 end\n",
      "Loss: 0.6444616018623441\n",
      "accuracy: 49.75124378109453\n",
      "epoch260 end\n",
      "Loss: 0.6652129819354148\n",
      "accuracy: 49.75124378109453\n",
      "epoch261 end\n",
      "Loss: 1.5866605006753358\n",
      "accuracy: 49.75124378109453\n",
      "epoch262 end\n",
      "Loss: 0.8873849639674998\n",
      "accuracy: 49.75124378109453\n",
      "epoch263 end\n",
      "Loss: 0.8535814144343647\n",
      "accuracy: 49.75124378109453\n",
      "epoch264 end\n",
      "Loss: 0.6366589167286884\n",
      "accuracy: 49.75124378109453\n",
      "epoch265 end\n",
      "Loss: 1.0715287925542194\n",
      "accuracy: 49.75124378109453\n",
      "epoch266 end\n",
      "Loss: 1.1047924764881136\n",
      "accuracy: 49.75124378109453\n",
      "epoch267 end\n",
      "Loss: 0.930415124769197\n",
      "accuracy: 49.75124378109453\n",
      "epoch268 end\n",
      "Loss: 0.9452098302787557\n",
      "accuracy: 49.75124378109453\n",
      "epoch269 end\n",
      "Loss: 1.5172439473190094\n",
      "accuracy: 49.75124378109453\n",
      "epoch270 end\n",
      "Loss: 1.0547900221379234\n",
      "accuracy: 49.75124378109453\n",
      "epoch271 end\n",
      "Loss: 1.5354276760643166\n",
      "accuracy: 49.75124378109453\n",
      "epoch272 end\n",
      "Loss: 0.8651838956154713\n",
      "accuracy: 49.75124378109453\n",
      "epoch273 end\n",
      "Loss: 1.1693629959720995\n",
      "accuracy: 49.75124378109453\n",
      "epoch274 end\n",
      "Loss: 1.4603753559597437\n",
      "accuracy: 49.75124378109453\n",
      "epoch275 end\n",
      "Loss: 1.3985086390726664\n",
      "accuracy: 49.75124378109453\n",
      "epoch276 end\n",
      "Loss: 0.5849226302218014\n",
      "accuracy: 49.75124378109453\n",
      "epoch277 end\n",
      "Loss: 1.2647272413750987\n",
      "accuracy: 49.75124378109453\n",
      "epoch278 end\n",
      "Loss: 0.8889773861899726\n",
      "accuracy: 49.75124378109453\n",
      "epoch279 end\n",
      "Loss: 1.8353442591124747\n",
      "accuracy: 49.75124378109453\n",
      "epoch280 end\n",
      "Loss: 0.9441505438211384\n",
      "accuracy: 49.75124378109453\n",
      "epoch281 end\n",
      "Loss: 0.8944756260850295\n",
      "accuracy: 49.75124378109453\n",
      "epoch282 end\n",
      "Loss: 1.5276798687743636\n",
      "accuracy: 49.75124378109453\n",
      "epoch283 end\n",
      "Loss: 1.1783783588788734\n",
      "accuracy: 49.75124378109453\n",
      "epoch284 end\n",
      "Loss: 0.7538200850345895\n",
      "accuracy: 49.75124378109453\n",
      "epoch285 end\n",
      "Loss: 0.715297904388287\n",
      "accuracy: 49.75124378109453\n",
      "epoch286 end\n",
      "Loss: 0.885215998792046\n",
      "accuracy: 49.75124378109453\n",
      "epoch287 end\n",
      "Loss: 0.6514269476416552\n",
      "accuracy: 49.75124378109453\n",
      "epoch288 end\n",
      "Loss: 1.3359104690892436\n",
      "accuracy: 49.75124378109453\n",
      "epoch289 end\n",
      "Loss: 1.1577174969398927\n",
      "accuracy: 49.75124378109453\n",
      "epoch290 end\n",
      "Loss: 1.0813537196788154\n",
      "accuracy: 49.75124378109453\n",
      "epoch291 end\n",
      "Loss: 0.8514849842031204\n",
      "accuracy: 49.75124378109453\n",
      "epoch292 end\n",
      "Loss: 0.689780008074573\n",
      "accuracy: 49.75124378109453\n",
      "epoch293 end\n",
      "Loss: 1.0233234451513724\n",
      "accuracy: 49.75124378109453\n",
      "epoch294 end\n",
      "Loss: 1.7327767810261465\n",
      "accuracy: 49.75124378109453\n",
      "epoch295 end\n",
      "Loss: 1.2749577560177126\n",
      "accuracy: 49.75124378109453\n",
      "epoch296 end\n",
      "Loss: 0.4986936658272965\n",
      "accuracy: 49.75124378109453\n",
      "epoch297 end\n",
      "Loss: 1.325510496178392\n",
      "accuracy: 49.75124378109453\n",
      "epoch298 end\n",
      "Loss: 1.5330841066509908\n",
      "accuracy: 49.75124378109453\n",
      "epoch299 end\n",
      "Loss: 1.5743644997453268\n",
      "accuracy: 49.75124378109453\n",
      "epoch300 end\n",
      "Loss: 0.7116094908137279\n",
      "accuracy: 49.75124378109453\n",
      "epoch301 end\n",
      "Loss: 0.9329810426436859\n",
      "accuracy: 49.75124378109453\n",
      "epoch302 end\n",
      "Loss: 0.8748867029470065\n",
      "accuracy: 49.75124378109453\n",
      "epoch303 end\n",
      "Loss: 0.5463971031042706\n",
      "accuracy: 49.75124378109453\n",
      "epoch304 end\n",
      "Loss: 0.9672636676080242\n",
      "accuracy: 49.75124378109453\n",
      "epoch305 end\n",
      "Loss: 0.894965102703609\n",
      "accuracy: 49.75124378109453\n",
      "epoch306 end\n",
      "Loss: 1.0758682428069064\n",
      "accuracy: 49.75124378109453\n",
      "epoch307 end\n",
      "Loss: 0.7144815410124866\n",
      "accuracy: 49.75124378109453\n",
      "epoch308 end\n",
      "Loss: 1.7974977409488728\n",
      "accuracy: 49.75124378109453\n",
      "epoch309 end\n",
      "Loss: 0.9427711587877201\n",
      "accuracy: 49.75124378109453\n",
      "epoch310 end\n",
      "Loss: 1.22996588632677\n",
      "accuracy: 49.75124378109453\n",
      "epoch311 end\n",
      "Loss: 0.8721716189291747\n",
      "accuracy: 49.75124378109453\n",
      "epoch312 end\n",
      "Loss: 0.7371122924987006\n",
      "accuracy: 49.75124378109453\n",
      "epoch313 end\n",
      "Loss: 1.4656189773755819\n",
      "accuracy: 49.75124378109453\n",
      "epoch314 end\n",
      "Loss: 1.1380903301758216\n",
      "accuracy: 49.75124378109453\n",
      "epoch315 end\n",
      "Loss: 0.6566104734761504\n",
      "accuracy: 49.75124378109453\n",
      "epoch316 end\n",
      "Loss: 1.2404475240396373\n",
      "accuracy: 49.75124378109453\n",
      "epoch317 end\n",
      "Loss: 1.0932645166697414\n",
      "accuracy: 49.75124378109453\n",
      "epoch318 end\n",
      "Loss: 1.2960610781656698\n",
      "accuracy: 49.75124378109453\n",
      "epoch319 end\n",
      "Loss: 1.4766739850051354\n",
      "accuracy: 49.75124378109453\n",
      "epoch320 end\n",
      "Loss: 0.5132724471859014\n",
      "accuracy: 49.75124378109453\n",
      "epoch321 end\n",
      "Loss: 0.6444818040804412\n",
      "accuracy: 49.75124378109453\n",
      "epoch322 end\n",
      "Loss: 0.7615506525063119\n",
      "accuracy: 49.75124378109453\n",
      "epoch323 end\n",
      "Loss: 1.0406650610059174\n",
      "accuracy: 49.75124378109453\n",
      "epoch324 end\n",
      "Loss: 0.7851721602566195\n",
      "accuracy: 49.75124378109453\n",
      "epoch325 end\n",
      "Loss: 1.0584269712580523\n",
      "accuracy: 49.75124378109453\n",
      "epoch326 end\n",
      "Loss: 1.0390656179044535\n",
      "accuracy: 49.75124378109453\n",
      "epoch327 end\n",
      "Loss: 1.3790253837295665\n",
      "accuracy: 49.75124378109453\n",
      "epoch328 end\n",
      "Loss: 1.4518190149338925\n",
      "accuracy: 49.75124378109453\n",
      "epoch329 end\n",
      "Loss: 0.8391953716043067\n",
      "accuracy: 49.75124378109453\n",
      "epoch330 end\n",
      "Loss: 1.317452892444621\n",
      "accuracy: 49.75124378109453\n",
      "epoch331 end\n",
      "Loss: 0.5656634239555981\n",
      "accuracy: 49.75124378109453\n",
      "epoch332 end\n",
      "Loss: 0.9114702015436825\n",
      "accuracy: 49.75124378109453\n",
      "epoch333 end\n",
      "Loss: 0.840695263456303\n",
      "accuracy: 49.75124378109453\n",
      "epoch334 end\n",
      "Loss: 1.1649203942952553\n",
      "accuracy: 49.75124378109453\n",
      "epoch335 end\n",
      "Loss: 1.387197744077314\n",
      "accuracy: 49.75124378109453\n",
      "epoch336 end\n",
      "Loss: 0.7124911447035612\n",
      "accuracy: 49.75124378109453\n",
      "epoch337 end\n",
      "Loss: 1.1357739201615864\n",
      "accuracy: 49.75124378109453\n",
      "epoch338 end\n",
      "Loss: 0.737715252752798\n",
      "accuracy: 49.75124378109453\n",
      "epoch339 end\n",
      "Loss: 1.030992595794006\n",
      "accuracy: 49.75124378109453\n",
      "epoch340 end\n",
      "Loss: 0.894960252207105\n",
      "accuracy: 49.75124378109453\n",
      "epoch341 end\n",
      "Loss: 1.2691307382252897\n",
      "accuracy: 49.75124378109453\n",
      "epoch342 end\n",
      "Loss: 0.6916414489804484\n",
      "accuracy: 49.75124378109453\n",
      "epoch343 end\n",
      "Loss: 1.0427327117660237\n",
      "accuracy: 49.75124378109453\n",
      "epoch344 end\n",
      "Loss: 0.5604283862714392\n",
      "accuracy: 49.75124378109453\n",
      "epoch345 end\n",
      "Loss: 1.1260625364809798\n",
      "accuracy: 49.75124378109453\n",
      "epoch346 end\n",
      "Loss: 0.995197278636742\n",
      "accuracy: 49.75124378109453\n",
      "epoch347 end\n",
      "Loss: 0.7196542659663805\n",
      "accuracy: 49.75124378109453\n",
      "epoch348 end\n",
      "Loss: 0.8476372731148026\n",
      "accuracy: 49.75124378109453\n",
      "epoch349 end\n",
      "Loss: 0.5289932943662573\n",
      "accuracy: 49.75124378109453\n",
      "epoch350 end\n",
      "Loss: 0.5687204379613408\n",
      "accuracy: 49.75124378109453\n",
      "epoch351 end\n",
      "Loss: 0.745181905085284\n",
      "accuracy: 49.75124378109453\n",
      "epoch352 end\n",
      "Loss: 0.9051479731527924\n",
      "accuracy: 49.75124378109453\n",
      "epoch353 end\n",
      "Loss: 0.7298210633779166\n",
      "accuracy: 49.75124378109453\n",
      "epoch354 end\n",
      "Loss: 0.7598904850552277\n",
      "accuracy: 49.75124378109453\n",
      "epoch355 end\n",
      "Loss: 1.057020431199228\n",
      "accuracy: 49.75124378109453\n",
      "epoch356 end\n",
      "Loss: 0.7342730686366589\n",
      "accuracy: 49.75124378109453\n",
      "epoch357 end\n",
      "Loss: 0.6335254375710493\n",
      "accuracy: 49.75124378109453\n",
      "epoch358 end\n",
      "Loss: 0.7820581697818285\n",
      "accuracy: 49.75124378109453\n",
      "epoch359 end\n",
      "Loss: 0.7003268912013313\n",
      "accuracy: 49.75124378109453\n",
      "epoch360 end\n",
      "Loss: 0.9219596682446201\n",
      "accuracy: 49.75124378109453\n",
      "epoch361 end\n",
      "Loss: 1.2125075730481418\n",
      "accuracy: 49.75124378109453\n",
      "epoch362 end\n",
      "Loss: 0.6757460407401229\n",
      "accuracy: 49.75124378109453\n",
      "epoch363 end\n",
      "Loss: 0.8349314068055509\n",
      "accuracy: 49.75124378109453\n",
      "epoch364 end\n",
      "Loss: 0.7002702453348938\n",
      "accuracy: 49.75124378109453\n",
      "epoch365 end\n",
      "Loss: 0.7058833520077412\n",
      "accuracy: 49.75124378109453\n",
      "epoch366 end\n",
      "Loss: 1.0295876322374056\n",
      "accuracy: 49.75124378109453\n",
      "epoch367 end\n",
      "Loss: 0.8848393200123991\n",
      "accuracy: 49.75124378109453\n",
      "epoch368 end\n",
      "Loss: 0.5131507102822689\n",
      "accuracy: 49.75124378109453\n",
      "epoch369 end\n",
      "Loss: 0.7903701217027503\n",
      "accuracy: 49.75124378109453\n",
      "epoch370 end\n",
      "Loss: 0.6992841799976925\n",
      "accuracy: 49.75124378109453\n",
      "epoch371 end\n",
      "Loss: 0.9291531979543964\n",
      "accuracy: 49.75124378109453\n",
      "epoch372 end\n",
      "Loss: 0.40583676416637116\n",
      "accuracy: 49.75124378109453\n",
      "epoch373 end\n",
      "Loss: 0.9029980685722014\n",
      "accuracy: 49.75124378109453\n",
      "epoch374 end\n",
      "Loss: 0.5449019188593495\n",
      "accuracy: 49.75124378109453\n",
      "epoch375 end\n",
      "Loss: 0.6093857632688944\n",
      "accuracy: 49.75124378109453\n",
      "epoch376 end\n",
      "Loss: 0.5293037354683343\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 49.75124378109453\n",
      "epoch377 end\n",
      "Loss: 1.0771111595198333\n",
      "accuracy: 49.75124378109453\n",
      "epoch378 end\n",
      "Loss: 0.7762463786748064\n",
      "accuracy: 49.75124378109453\n",
      "epoch379 end\n",
      "Loss: 0.7634276679931647\n",
      "accuracy: 49.75124378109453\n",
      "epoch380 end\n",
      "Loss: 1.5204302659759779\n",
      "accuracy: 49.75124378109453\n",
      "epoch381 end\n",
      "Loss: 0.8572946174842745\n",
      "accuracy: 49.75124378109453\n",
      "epoch382 end\n",
      "Loss: 0.4854135134597976\n",
      "accuracy: 49.75124378109453\n",
      "epoch383 end\n",
      "Loss: 0.7717784481737886\n",
      "accuracy: 49.75124378109453\n",
      "epoch384 end\n",
      "Loss: 1.405262220081111\n",
      "accuracy: 49.75124378109453\n",
      "epoch385 end\n",
      "Loss: 0.8294847528214835\n",
      "accuracy: 49.75124378109453\n",
      "epoch386 end\n",
      "Loss: 0.6761742261563853\n",
      "accuracy: 49.75124378109453\n",
      "epoch387 end\n",
      "Loss: 0.5299793250941075\n",
      "accuracy: 49.75124378109453\n",
      "epoch388 end\n",
      "Loss: 0.7273883444238135\n",
      "accuracy: 49.75124378109453\n",
      "epoch389 end\n",
      "Loss: 0.7549706603277191\n",
      "accuracy: 49.75124378109453\n",
      "epoch390 end\n",
      "Loss: 0.9546722508490639\n",
      "accuracy: 49.75124378109453\n",
      "epoch391 end\n",
      "Loss: 0.9516227794808834\n",
      "accuracy: 49.75124378109453\n",
      "epoch392 end\n",
      "Loss: 1.035199434098685\n",
      "accuracy: 49.75124378109453\n",
      "epoch393 end\n",
      "Loss: 0.6623375692507716\n",
      "accuracy: 49.75124378109453\n",
      "epoch394 end\n",
      "Loss: 0.9297283843682578\n",
      "accuracy: 49.75124378109453\n",
      "epoch395 end\n",
      "Loss: 0.5434253613393841\n",
      "accuracy: 49.75124378109453\n",
      "epoch396 end\n",
      "Loss: 1.1441124896291728\n",
      "accuracy: 49.75124378109453\n",
      "epoch397 end\n",
      "Loss: 0.7863628024670858\n",
      "accuracy: 49.75124378109453\n",
      "epoch398 end\n",
      "Loss: 0.802237830748719\n",
      "accuracy: 49.75124378109453\n",
      "epoch399 end\n",
      "Loss: 0.6797657227121613\n",
      "accuracy: 49.75124378109453\n",
      "epoch400 end\n",
      "Loss: 0.6385358771388868\n",
      "accuracy: 49.75124378109453\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'accuracy_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-8be299d9ac94>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;31m#accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'accuracy_list' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "epoch_times =400\n",
    "\n",
    "load_batch = 100\n",
    "mini_batch_size = 50\n",
    "learning_rate = 1\n",
    "\n",
    "w_tr = np.random.rand(200000)\n",
    "b_tr = np.random.rand()\n",
    "\n",
    "Loss_list = []\n",
    "acc_list = []\n",
    "for _ in range(epoch_times):\n",
    "    p_trainbatch, n_trainbatch = load_train(load_batch)\n",
    "    w_, b_, Loss = training(w_tr,b_tr, p_trainbatch,n_trainbatch,learning_rate,mini_batch_size)\n",
    "    print(\"epoch\" + str(_ + 1) + \" end\")\n",
    "    print(\"Loss: \"+str(Loss))\n",
    "    accuracy = accuracy_eval( w_, b_ )\n",
    "    print(\"accuracy: \"+str(accuracy))\n",
    "    w_tr = w_\n",
    "    b_tr = b_\n",
    "    Loss_list.append(Loss)\n",
    "    acc_list.append(accuracy)\n",
    "\n",
    "plt.plot(Loss_list)\n",
    "plt.show()#Loss\n",
    "print()\n",
    "plt.figure()\n",
    "plt.plot(accuracy_list)\n",
    "plt.show()\n",
    "#accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./w_record_mb50_lr1\",\"wb\") as f:\n",
    "    pickle.dump(w_tr,f)\n",
    "    \n",
    "with open(\"./b_record_mb50_lr1\",\"wb\") as f:\n",
    "    pickle.dump(b_tr,f)\n",
    "    \n",
    "with open(\"./record/acc_record_mb50_lr1\",\"wb\") as f:\n",
    "    pickle.dump(acc_list,f)\n",
    "    \n",
    "with open(\"./record/loss_record_mb50_lr1\",\"wb\") as f:\n",
    "    pickle.dump(Loss_list,f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
